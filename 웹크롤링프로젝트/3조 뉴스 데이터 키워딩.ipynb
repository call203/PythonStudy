{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3조 News 데이터 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sbs():\n",
    "    \n",
    "    base_url = 'https://news.sbs.co.kr/news/newsSection.do'\n",
    "\n",
    "    params = {\n",
    "        'sectionType' : '01',\n",
    "        'plink' : 'SNB',\n",
    "        'cooper' : 'SBSNEWS',\n",
    "        'pageIdx' : 1,\n",
    "        'pageDate' : 20200806\n",
    "    }\n",
    "\n",
    "    index_list = ['01', '02', '03', '07', '08', '14', '09'] # SectionType ( 카테고리를 가져오기 위한 리스트)\n",
    "\n",
    "    index_str_list = ['정치', '경제', '사회', '국제', '생활&문화', '연예', '스포츠'] # SectionType = 카테고리 이름\n",
    "\n",
    "    index_point = 0 # 리스트를 가져 오기 위한 index\n",
    "\n",
    "    txt_file_name = ['a1.txt', 'b1.txt', 'c1.txt', 'd1.txt', 'e1.txt', 'f1.txt', 'g1.txt'] # 각 카테고리별 저장을 위한 text 파일 list\n",
    "\n",
    "\n",
    "    f = open(txt_file_name[index_point], \"w+t\") # 무조건 처음 시작할 때 지우고 다시만든다.\n",
    "\n",
    "    while True:\n",
    "\n",
    "        resp = requests.get(base_url, params = params)\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "        news_list_tags = soup.select('#container > div > div.w_news_list.type_issue > ul > li > a.news')\n",
    "\n",
    "\n",
    "\n",
    "        if(len(news_list_tags) == 0): # 더이상 탐색할 페이지가 없을때\n",
    "\n",
    "            if(index_point + 1 == 7): # section 및 page 다 탐색 -> 종료\n",
    "\n",
    "                f.close()\n",
    "                break\n",
    "\n",
    "            else:\n",
    "\n",
    "                f.close()\n",
    "\n",
    "                index_point += 1\n",
    "\n",
    "                f = open(txt_file_name[index_point], \"w+t\")\n",
    "\n",
    "                params['sectionType'] = index_list[index_point]\n",
    "\n",
    "                params['pageIdx'] = 1\n",
    "\n",
    "                continue\n",
    "\n",
    "            break\n",
    "\n",
    "        for i in news_list_tags: # 파일을 쓴다.\n",
    "\n",
    "            dt_tags = i.find_all('strong')\n",
    "            title_tag = dt_tags[0].text\n",
    "            f.write(title_tag)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        params['pageIdx'] += 1\n",
    "\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JTBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jtbc_news_list(day):\n",
    "    \n",
    "    # 카테고리 'scode'를 dict로 정의.\n",
    "    menu_list = {\n",
    "        '속보' : 0,\n",
    "        '정치' : 10,\n",
    "        '경제' : 20,\n",
    "        '사회' : 30,\n",
    "        '국제' : 40,\n",
    "        '문화' : 50,\n",
    "        '연예' : 60,\n",
    "        '스포츠' : 70,\n",
    "        '날씨': 80\n",
    "    }\n",
    "    \n",
    "    base_url ='http://news.jtbc.joins.com/section/list.aspx?'\n",
    "    params = {\n",
    "        'scode' : 0,\n",
    "        'pdate' : day,\n",
    "        'pgi' : 0\n",
    "    }\n",
    "    \n",
    "    # text 파일 통합 위해서 이름명 설정. 날씨 카테고리 문화에 합침.\n",
    "    scode_list = {\n",
    "        10 : 'a',\n",
    "        20 : 'b',\n",
    "        30 : 'c',\n",
    "        40 : 'd',\n",
    "        50 : 'e',\n",
    "        60 : 'f',\n",
    "        70 : 'g',\n",
    "        80 : 'e'\n",
    "    }\n",
    "    \n",
    "    for k in range(8):\n",
    "        news_list = []\n",
    "        params['scode'] +=10 # 카테고리 넘기기\n",
    "        params['pgi'] = 0\n",
    "        \n",
    "        while True:\n",
    "            params['pgi'] +=1 # 페이지 넘기기\n",
    "\n",
    "            resp = requests.get(base_url, params=params)\n",
    "            soup = BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "            news_tags = soup.find('ul', id='section_list')\n",
    "            news_list_tags = news_tags.find_all('dt', class_='title_cr') # 뉴스 타이틀 tag\n",
    "\n",
    "\n",
    "            if len(news_list_tags)==0: # 마지막 페이지에서 더 넘어가면 while문 탈출.\n",
    "                break\n",
    "\n",
    "            for tags in news_list_tags:\n",
    "                news_title = tags.text\n",
    "\n",
    "                news_list.append(\n",
    "                    news_title.strip()\n",
    "                )\n",
    "        \n",
    "    \n",
    "        file_name = scode_list[params['scode']]+'2.txt' # 카테고리별 params 숫자를 받아 파일명 key값으로 입력 -> 알파벳 출력\n",
    "        \n",
    "        \n",
    "        # 날씨 카테고리 내용 문화영역에 추가하기. 나머지는 그냥 파일 생성.\n",
    "        if params['scode'] == 80:\n",
    "            file1 = open(file_name, 'at')\n",
    "        else:\n",
    "            file1 = open(file_name, 'w')\n",
    "        \n",
    "        for i in news_list:\n",
    "            file1.write(i+\"\\n\")\n",
    "            \n",
    "        file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오늘 날짜 \n",
    "import re\n",
    "import datetime\n",
    "\n",
    "def make_f(newlist):\n",
    "    # 파일명\n",
    "    menu_list=['a3.txt','c3.txt','b3.txt',\n",
    "          'd3.txt','e3.txt','g3.txt']\n",
    "    for idx, i in enumerate(menu_list):\n",
    "        f = open(i,'w')\n",
    "        for j in newlist[idx]:\n",
    "            msg = j\n",
    "            f.write(j+\"\\n\")\n",
    "        f.close()\n",
    "        #main()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#스포츠 메뉴의 구조가 달라 따로 구함\n",
    "def sport(Sports_list, day):\n",
    "    for i in range(3):\n",
    "        params={\n",
    "            'page':i+1,\n",
    "            's_mcd':'0107'\n",
    "        }\n",
    "        resp = requests.get('https://www.ytn.co.kr/photo/photo_list.php',params=params)\n",
    "        soup = BeautifulSoup(resp.text, 'lxml')\n",
    "        #리스트\n",
    "        sec_tag = soup.find(\"div\", id=\"ytn_list_v2014\")\n",
    "        dl_tag=sec_tag.find_all(\"dl\",class_='photo_list')\n",
    "        \n",
    "        for j in dl_tag:\n",
    "            # 날짜\n",
    "            date_tag = j.find('dd',class_='date')\n",
    "            date_d = date_tag.text\n",
    "            date = date_d.split(\" \")\n",
    "            date = date[0].replace(\"[\",\"\")\n",
    "\n",
    "\n",
    "            if day == date:\n",
    "                dt_tag =j.find_all('dt')\n",
    "                a_tag = dt_tag[0].find(\"a\")\n",
    "                title = a_tag.text\n",
    "                \n",
    "                \n",
    "                if title in Sports_list:\n",
    "                    continue\n",
    "                    \n",
    "                Sports_list.append(title)\n",
    "                \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ytn():\n",
    "    \n",
    "\n",
    "    now = datetime.datetime.now() - datetime.timedelta(days=1)\n",
    "    day = now.strftime(\"%Y-%m-%d\")\n",
    "    print(day)\n",
    "\n",
    "\n",
    "\n",
    "    # YTN사이트\n",
    "    url = 'https://www.ytn.co.kr/news/news_list_0101.html'\n",
    "\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.content, 'lxml')\n",
    "    menu = soup.find(\"ul\",id='sub_1')\n",
    "    li_tag = menu.find_all('li',recursive=False)\n",
    "\n",
    "    a=[]\n",
    "    politics_list=[]\n",
    "    economy_list=[]\n",
    "    social_list=[]\n",
    "    domestic_list=[]\n",
    "    International_list=[]\n",
    "    Science_list=[]\n",
    "    Sports_list=[]\n",
    "    culture_list =[]\n",
    "\n",
    "\n",
    "    # 카테고리마다 뉴스 제목 리스트\n",
    "    newlist = [politics_list,economy_list,social_list,domestic_list,\n",
    "               International_list,Science_list,culture_list]\n",
    "\n",
    "\n",
    "    #3,4,5,6,7,8,9,10,11\n",
    "    url2 = 'https://www.ytn.co.kr/news/news_list.php?'\n",
    "    for idx in range(3,11,1):\n",
    "        #메뉴이동\n",
    "        a_tag =li_tag[idx].find('a')\n",
    "        move = a_tag.get('href')\n",
    "        a = re.findall('\\d+',move)\n",
    "\n",
    "        if idx == 10:\n",
    "            sport(Sports_list, day)\n",
    "            newlist.remove(domestic_list)\n",
    "            newlist.remove(Science_list)\n",
    "            newlist.append(Sports_list)\n",
    "            make_f(newlist)\n",
    "            break\n",
    "\n",
    "\n",
    "        for i in range(3):\n",
    "            params={\n",
    "                'page':i+1,\n",
    "                's_mcd':a[0]\n",
    "            }\n",
    "            resp = requests.get(url2,params=params)\n",
    "            soup = BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "            #리스트\n",
    "            sec_tag = soup.find(\"div\", id=\"ytn_list_v2014\")\n",
    "\n",
    "            span_tag=sec_tag.find_all(\"dl\", class_=\"news_list_v2014\")\n",
    "\n",
    "            for j in span_tag:\n",
    "                # 날짜\n",
    "                date_tag = j.find('dd',class_='date')\n",
    "                date_d = date_tag.text\n",
    "                date = date_d.split(\" \")\n",
    "                date = date[0].replace(\"[\",\"\")\n",
    "\n",
    "\n",
    "                if day == date:\n",
    "                    dt_tag =j.find_all('dt')\n",
    "                    a_tag = dt_tag[0].find(\"a\")\n",
    "                    title = a_tag.text\n",
    "\n",
    "\n",
    "                    if title in newlist[idx-3]:\n",
    "                        continue\n",
    "                    if idx == 6 or idx == 8:\n",
    "                        newlist[6].append(title)\n",
    "\n",
    "                    else:    \n",
    "                        newlist[idx-3].append(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "##########프로젝트 MBN 홈페이지 긁어오는 함수 코드##########\n",
    "############################################################\n",
    "\n",
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "\n",
    "def MBN_News_Function():\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    reresult_list=[]\n",
    "    while count<7:\n",
    "        \n",
    "        if count==0:\n",
    "            category_s='politics'\n",
    "            MBN_url='https://www.mbn.co.kr/news/politics/'\n",
    "        \n",
    "        if count==1:\n",
    "            category_s='economy'\n",
    "            MBN_url='https://www.mbn.co.kr/news/economy/'\n",
    "\n",
    "        elif count==2:\n",
    "            category_s='society'\n",
    "            MBN_url='https://www.mbn.co.kr/news/society/'\n",
    "\n",
    "        elif count==3:\n",
    "            category_s='world'\n",
    "            MBN_url='https://www.mbn.co.kr/news/world/'\n",
    "\n",
    "        elif count==4:\n",
    "            category_s='culture'\n",
    "            MBN_url='https://www.mbn.co.kr/news/culture/'\n",
    "\n",
    "        elif count==5:\n",
    "            category_s='entertain'\n",
    "            MBN_url='https://www.mbn.co.kr/news/entertain/'        \n",
    "\n",
    "        elif count==6:\n",
    "            category_s='sports'\n",
    "            MBN_url='https://www.mbn.co.kr/news/sports/'\n",
    "\n",
    "        result_list=[]\n",
    "        for i in range(1,8): #페이지번호\n",
    "            params={\n",
    "                'page':i,\n",
    "                'vod':None,\n",
    "                'category':category_s\n",
    "            }\n",
    "            resp=requests.get(MBN_url, params=params)\n",
    "\n",
    "            resp.encoding='eur-kr'\n",
    "            soup=BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "            MBN_news_list=soup.select('div.list_area > dl.article_list > dt.tit > a')\n",
    "            MBN_news_list_date=soup.select('div.list_area > dl.article_list > dd.desc > span.date')\n",
    "\n",
    "            news_list=[]\n",
    "            for news,date in zip(MBN_news_list, MBN_news_list_date):\n",
    "\n",
    "                news=news.text.strip() #제목 내 띄어쓰기 제거\n",
    "                news=news.replace(\"\\'\" , \" \") #제목 내 따옴표 제거\n",
    "                news=news.replace(\"♥\" , \" \") #제목 내 따옴표 제거\n",
    "                news=news.replace(\"[포토]\",\" \") #제목 내 [포토] 제거\n",
    "\n",
    "                date=date.text[0:10].replace(\"-\",\"\")\n",
    "\n",
    "                if date == '20200806': #날짜 수정하면 됨\n",
    "                    news_list.append(news)\n",
    "            result_list.extend(news_list)\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "        reresult_list.append(result_list)\n",
    "    return reresult_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "#########프로젝트 MBN 메모장으로 꺼내오는 함수 코드#########\n",
    "############################################################\n",
    "\n",
    "# a1, 2, 3, 4 -> 정치\n",
    "# b1, 2, 3, 4 -> 경제\n",
    "# c1, 2, 3, 4 -> 사회\n",
    "# d1, 2, 3, 4 -> 국제\n",
    "# e1, 2, 3, 4 -> 생활&문화, 문화 + mbn생활건강 +ytn전국,과학\n",
    "# f1, 2, 3, 4 -> 연예\n",
    "# g1, 2, 3, 4 -> 스포츠\n",
    "\n",
    "def MBN():\n",
    "\n",
    "    title_list=['a','b','c','d','e','f','g']\n",
    "    #나중에 j를 e로 바꿔서 추가해야함!\n",
    "\n",
    "    f_list=[]\n",
    "    for title in title_list:\n",
    "        f=open('{}4.txt'.format(title),'w')    \n",
    "        f_list.append(f)\n",
    "\n",
    "\n",
    "    MBN=MBN_News_Function()   # 2중리스트로 옴. [[1,2,3...] , [1,2,3...] , [1,2,3...]]\n",
    "\n",
    "\n",
    "    for i, f in zip(MBN,f_list):\n",
    "        for j in i:\n",
    "            f.write(j)\n",
    "            f.write('\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아시아경제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "##########프로젝트 MBN 홈페이지 긁어오는 함수 코드##########\n",
    "############################################################\n",
    "\n",
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "# a1, 2, 3, 4 -> 정치\n",
    "# b1, 2, 3, 4 -> 경제\n",
    "# c1, 2, 3, 4 -> 사회\n",
    "# d1, 2, 3, 4 -> 국제\n",
    "# e1, 2, 3, 4 -> 생활&문화, 문화 + mbn생활건강 +ytn전국,과학\n",
    "# f1, 2, 3, 4 -> 연예\n",
    "# g1, 2, 3, 4 -> 스포츠\n",
    "\n",
    "def ASIA_News_Function():\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    reresult_list=[]\n",
    "    while count<6:\n",
    "        \n",
    "        if count==0:\n",
    "            category_s='politics'\n",
    "            #ASIA_url='https://www.asiae.co.kr/list/politics-all/1'\n",
    "            ASIA_url='https://www.asiae.co.kr/news/list.htm?sec=0100'\n",
    "            \n",
    "        if count==1:\n",
    "            category_s='economy'\n",
    "            ASIA_url='https://www.asiae.co.kr/news/list.htm?sec=0200'\n",
    "\n",
    "        elif count==2:\n",
    "            category_s='society'\n",
    "            ASIA_url='https://www.asiae.co.kr/news/list.htm?sec=0700'\n",
    "\n",
    "        elif count==3:\n",
    "            category_s='world'\n",
    "            ASIA_url='https://www.asiae.co.kr/news/list.htm?sec=0600'\n",
    "\n",
    "        elif count==4:\n",
    "            category_s='culture'\n",
    "            ASIA_url='https://www.asiae.co.kr/news/list.htm?sec=0800'\n",
    "\n",
    "        elif count==5:\n",
    "            category_s='entertain'\n",
    "            ASIA_url='https://www.asiae.co.kr/news/list.htm?sec=1000'\n",
    "\n",
    "        result_list=[]\n",
    "        for i in range(2,3): #페이지번호\n",
    "\n",
    "            resp=requests.get(ASIA_url)\n",
    "            \n",
    "            resp.encoding='eur-kr'\n",
    "            soup=BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "            ASIA_news_list=soup.select('div.cont_listarea > div > div.listsm_type > h3.l_fsttit > a')\n",
    "        \n",
    "            \n",
    "            news_list=[]\n",
    "            for news in ASIA_news_list:\n",
    "                \n",
    "                #본문\n",
    "                news=news.text.strip() #제목 내 띄어쓰기 제거\n",
    "\n",
    "                news_list.append(news)\n",
    "                    \n",
    "                    \n",
    "            result_list.extend(news_list)\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "        reresult_list.append(result_list)\n",
    "    return reresult_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "#########프로젝트 MBN 메모장으로 꺼내오는 함수 코드#########\n",
    "############################################################\n",
    "\n",
    "# a1, 2, 3, 4 -> 정치\n",
    "# b1, 2, 3, 4 -> 경제\n",
    "# c1, 2, 3, 4 -> 사회\n",
    "# d1, 2, 3, 4 -> 국제\n",
    "# e1, 2, 3, 4 -> 생활&문화, 문화 + mbn생활건강 +ytn전국,과학\n",
    "# f1, 2, 3, 4 -> 연예\n",
    "# g1, 2, 3, 4 -> 스포츠\n",
    "\n",
    "def ASIA():\n",
    "\n",
    "    title_list=['a','b','c','d','e','f']\n",
    "    #나중에 j를 e로 바꿔서 추가해야함!\n",
    "\n",
    "    f_list=[]\n",
    "    for title in title_list:\n",
    "        f=open('{}5.txt'.format(title),'w')    \n",
    "        f_list.append(f)\n",
    "\n",
    "\n",
    "    ASIA=ASIA_News_Function()\n",
    "\n",
    "    \n",
    "    for i, f in zip(ASIA, f_list):\n",
    "        for j in i:\n",
    "            f.write(j)\n",
    "            f.write('\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------카테고리[정치]--------------------\n",
      " 지원            \t25\n",
      " 원피스           \t24\n",
      " 호정            \t21\n",
      " 방류            \t19\n",
      " 북한            \t16\n",
      " 통합            \t15\n",
      " 특별            \t14\n",
      " 정부            \t13\n",
      " 논란            \t12\n",
      " 민주당           \t12\n",
      " 코로나           \t11\n",
      " 유착            \t11\n",
      " 뉴스            \t11\n",
      " 국회            \t10\n",
      " 김정은           \t9\n",
      " 유감            \t9\n",
      " 부동산           \t9\n",
      " 농지            \t8\n",
      " 윤석열           \t8\n",
      " 주호영           \t8\n",
      " 봉쇄            \t8\n",
      " 지역            \t8\n",
      " 조원            \t7\n",
      " 통보            \t7\n",
      " 개성            \t7\n",
      " 주택            \t7\n",
      " 대동강           \t7\n",
      " 대통령           \t7\n",
      " 황강            \t6\n",
      " 긴급            \t6\n",
      " 여성            \t6\n",
      " 지시            \t6\n",
      " 사전            \t6\n",
      " 안철수           \t6\n",
      " 정무            \t6\n",
      " 수위            \t6\n",
      " 방문            \t6\n",
      " 재난            \t6\n",
      " 해임            \t6\n",
      " 일방            \t5\n",
      " 한상혁           \t5\n",
      " 부지            \t5\n",
      " 위반            \t5\n",
      " 총리            \t5\n",
      " 대북            \t5\n",
      " 공개            \t5\n",
      " 발언            \t5\n",
      " 수도            \t5\n",
      " 아침            \t5\n",
      " 이인영           \t5\n",
      "\n",
      " ********** 순위 ************* \n",
      "\n",
      "\t 1순위:지원\n",
      "\t 2순위:원피스\n",
      "\t 3순위:호정\n",
      "\n",
      " ********** 기사 ************* \n",
      "\n",
      "1,000만 달러 영유아 지원 결정…김정은 태도 바뀔까\n",
      "\n",
      "[전화 연결] 류호정 \"원피스 논란, 여성·청년 정치인 편견\"\n",
      "\n",
      "[전화 연결] 류호정 \"원피스 논란, 여성·청년 정치인 편견\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------카테고리[경제]--------------------\n",
      " 주택            \t8\n",
      " 부동산           \t8\n",
      " 코로나           \t7\n",
      " 서울            \t7\n",
      " 셋값            \t5\n",
      " 정책            \t5\n",
      " 영업            \t5\n",
      " 인기            \t4\n",
      " 공직자           \t4\n",
      " 보도            \t4\n",
      " 개월            \t4\n",
      " 내일            \t4\n",
      " 침수            \t4\n",
      " 이재용           \t4\n",
      " 단독            \t4\n",
      " 도로            \t4\n",
      " 피해            \t4\n",
      " 임대            \t4\n",
      " 한국            \t4\n",
      " 논의            \t4\n",
      " 온라인           \t3\n",
      " 시대            \t3\n",
      " 대한항공          \t3\n",
      " 허위            \t3\n",
      " 대폭            \t3\n",
      " 해외            \t3\n",
      " 방안            \t3\n",
      " 고위            \t3\n",
      " 상승            \t3\n",
      " 시설            \t3\n",
      " 교회            \t3\n",
      " 검찰            \t3\n",
      " 기소            \t3\n",
      " 결론            \t3\n",
      " 파업            \t3\n",
      " 범람            \t3\n",
      " 하천            \t3\n",
      " 투자            \t3\n",
      " 논란            \t3\n",
      " 기자            \t3\n",
      " 안전            \t3\n",
      " 최대            \t3\n",
      " 오늘            \t3\n",
      " 신규            \t3\n",
      " 정보            \t3\n",
      " 협회            \t3\n",
      " 시청            \t2\n",
      " 광고            \t2\n",
      " 한상혁           \t2\n",
      " 유착            \t2\n",
      "\n",
      " ********** 순위 ************* \n",
      "\n",
      "\t 1순위:주택\n",
      "\t 2순위:부동산\n",
      "\t 3순위:코로나\n",
      "\n",
      " ********** 기사 ************* \n",
      "\n",
      "\"다주택 공직자는 부동산 정책 못 만들게 하라\"\n",
      "\n",
      "\"다주택 공직자는 부동산 정책 못 만들게 하라\"\n",
      "\n",
      "'온라인 언팩' 5,600만 명 시청…코로나 시대엔 비대면\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------카테고리[사회]--------------------\n",
      " 뉴스            \t21\n",
      " 주민            \t18\n",
      " 서울            \t17\n",
      " 수위            \t17\n",
      " 통제            \t16\n",
      " 의암댐           \t15\n",
      " 한강            \t15\n",
      " 대피            \t15\n",
      " 피해            \t12\n",
      " 마을            \t12\n",
      " 잠수교           \t11\n",
      " 구조            \t11\n",
      " 홍수            \t11\n",
      " 곳곳            \t11\n",
      " 코로나           \t11\n",
      " 도로            \t10\n",
      " 주의보           \t10\n",
      " 실종            \t10\n",
      " 내일            \t9\n",
      " 침수            \t9\n",
      " 올림픽대로         \t9\n",
      " 검찰            \t9\n",
      " 지역            \t9\n",
      " 전국            \t9\n",
      " 선박            \t9\n",
      " 사망            \t9\n",
      " 정부            \t9\n",
      " 전공            \t9\n",
      " 수색            \t8\n",
      " 골프장           \t8\n",
      " 수초            \t8\n",
      " 집단            \t8\n",
      " 집중호우          \t7\n",
      " 발생            \t7\n",
      " 매몰            \t7\n",
      " 기자            \t7\n",
      " 확진            \t7\n",
      " 경기            \t7\n",
      " 전복            \t7\n",
      " 영상            \t7\n",
      " 한동훈           \t7\n",
      " 파업            \t7\n",
      " 범람            \t7\n",
      " 유착            \t7\n",
      " 윤석열           \t7\n",
      " 현장            \t6\n",
      " 실종자           \t6\n",
      " 작업            \t6\n",
      " 의료            \t6\n",
      " 일대            \t6\n",
      "\n",
      " ********** 순위 ************* \n",
      "\n",
      "\t 1순위:뉴스\n",
      "\t 2순위:주민\n",
      "\t 3순위:서울\n",
      "\n",
      " ********** 기사 ************* \n",
      "\n",
      "오늘의 주요뉴스\n",
      "\n",
      "제한보다 높은 군남댐 수위…파주 주민 대피령 유지\n",
      "\n",
      "집중호우로 서울서 이재민 29명 발생…포트홀 2천302건\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------카테고리[국제]--------------------\n",
      " 코로나           \t40\n",
      " 트럼프           \t40\n",
      " 폭발            \t32\n",
      " 베이루트          \t25\n",
      " 레바논           \t23\n",
      " 사망            \t21\n",
      " 미국            \t20\n",
      " 중국            \t18\n",
      " 참사            \t15\n",
      " 협상            \t14\n",
      " 확진            \t12\n",
      " 백신            \t12\n",
      " 공격            \t10\n",
      " 방위            \t10\n",
      " 부상            \t10\n",
      " 영상            \t9\n",
      " 일본            \t9\n",
      " 대선            \t9\n",
      " 신규            \t8\n",
      " 금지            \t7\n",
      " 특별            \t7\n",
      " 피해            \t7\n",
      " 실업            \t6\n",
      " 틱톡            \t6\n",
      " 세계            \t6\n",
      " 논란            \t6\n",
      " 국방            \t6\n",
      " 우선            \t6\n",
      " 과제            \t6\n",
      " 북한            \t6\n",
      " 대북            \t6\n",
      " 속보            \t6\n",
      " 차관            \t5\n",
      " 한국            \t5\n",
      " 경고            \t5\n",
      " 동맹국           \t5\n",
      " 파우치           \t5\n",
      " 페이스북          \t5\n",
      " 삭제            \t5\n",
      " 압박            \t5\n",
      " 원인            \t5\n",
      " 질산암모늄         \t5\n",
      " 사태            \t5\n",
      " 대표            \t5\n",
      " 준비            \t5\n",
      " 제거            \t5\n",
      " 사고            \t5\n",
      " 재선            \t5\n",
      " 백악관           \t5\n",
      " 수락            \t5\n",
      "\n",
      " ********** 순위 ************* \n",
      "\n",
      "\t 1순위:코로나\n",
      "\t 2순위:트럼프\n",
      "\t 3순위:폭발\n",
      "\n",
      " ********** 기사 ************* \n",
      "\n",
      "창궐 더 심해졌다…전 세계 코로나19 확진 1천900만 명\n",
      "\n",
      "지지율 낮아도 돈은 트럼프 캠프로…7월 1천952억 원 모금\n",
      "\n",
      "프랑스 마크롱, 폭발 참사 레바논 방문…\"개혁 안 하면 침몰\" 경고\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------카테고리[생활&문화]--------------------\n",
      " 실종            \t16\n",
      " 날씨            \t13\n",
      " 의암호           \t12\n",
      " 선박            \t11\n",
      " 사망            \t11\n",
      " 서울            \t9\n",
      " 침몰            \t9\n",
      " 피해            \t9\n",
      " 복구            \t9\n",
      " 주민            \t9\n",
      " 춘천            \t8\n",
      " 마을            \t8\n",
      " 대피            \t7\n",
      " 내일            \t6\n",
      " 호우            \t6\n",
      " 작업            \t6\n",
      " 철원            \t6\n",
      " 중부            \t5\n",
      " 특보            \t5\n",
      " 최대            \t5\n",
      " 전국            \t5\n",
      " 코로나           \t5\n",
      " 재민            \t5\n",
      " 영상            \t5\n",
      " 한탄강           \t5\n",
      " 시각            \t5\n",
      " 경찰            \t5\n",
      " 충청            \t4\n",
      " 강풍            \t4\n",
      " 비바람           \t4\n",
      " 공개            \t4\n",
      " 빌라            \t4\n",
      " 전복            \t4\n",
      " 대피소           \t4\n",
      " 구간            \t4\n",
      " 부산            \t4\n",
      " 절반            \t4\n",
      " 장맛비           \t3\n",
      " 시작            \t3\n",
      " 이남            \t3\n",
      " 린다            \t3\n",
      " 집중호우          \t3\n",
      " 충남            \t3\n",
      " 최고            \t3\n",
      " 전문            \t3\n",
      " 출시            \t3\n",
      " 구조            \t3\n",
      " 경기            \t3\n",
      " 통제            \t3\n",
      " 특별            \t3\n",
      "\n",
      " ********** 순위 ************* \n",
      "\n",
      "\t 1순위:실종\n",
      "\t 2순위:날씨\n",
      "\t 3순위:의암호\n",
      "\n",
      " ********** 기사 ************* \n",
      "\n",
      "춘천 의암호에서 선박 3척 침몰...1명 사망· 5명 실종\n",
      "\n",
      "[날씨] 100mm↑ 쏟아진 중부…장맛비, 언제까지 오나\n",
      "\n",
      "춘천 의암호에서 선박 3척 침몰...1명 사망· 5명 실종\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------카테고리[연예]--------------------\n",
      " 공개            \t6\n",
      " 스브            \t3\n",
      " 스타            \t3\n",
      " 오취            \t3\n",
      " 마음            \t3\n",
      " 송지효           \t3\n",
      " 영화            \t3\n",
      " 권민아           \t3\n",
      " 입장            \t3\n",
      " 괴한            \t3\n",
      " 난동            \t3\n",
      " 쯔양            \t3\n",
      " 골목            \t3\n",
      " 식당            \t3\n",
      " 인터뷰           \t3\n",
      " 엄정화           \t3\n",
      " 소유            \t3\n",
      " 합류            \t2\n",
      " 고백            \t2\n",
      " 깜짝            \t2\n",
      " 선물            \t2\n",
      " 스크린           \t2\n",
      " 김호중           \t2\n",
      " 사실            \t2\n",
      " 조정석           \t2\n",
      " 거미            \t2\n",
      " 득녀            \t2\n",
      " 아기            \t2\n",
      " 매우            \t2\n",
      " 멤버            \t2\n",
      " 지민            \t2\n",
      " 황정민           \t2\n",
      " 아나운서          \t2\n",
      " 폭소            \t2\n",
      " 이유            \t2\n",
      " 현장            \t2\n",
      " 김형규           \t2\n",
      " 은퇴            \t2\n",
      " 닭강정           \t2\n",
      " 창동            \t2\n",
      " 흑인            \t2\n",
      " 임영웅           \t2\n",
      " 비밀            \t2\n",
      " 오창석           \t2\n",
      " 이채            \t2\n",
      " 결별설           \t2\n",
      " 결혼설           \t2\n",
      " 오케이           \t2\n",
      " 마담            \t2\n",
      " 모두            \t2\n",
      "\n",
      " ********** 순위 ************* \n",
      "\n",
      "\t 1순위:공개\n",
      "\t 2순위:스브\n",
      "\t 3순위:스타\n",
      "\n",
      " ********** 기사 ************* \n",
      "\n",
      "계속된 개봉 연기 끝에…영화 '뮬란', 온라인 공개 결정\n",
      "\n",
      "[스브스타] \"미쓰에이 데뷔 준비→원더걸스 합류\"…혜림, 힘들었던 과거 고백\n",
      "\n",
      "[스브스타] \"미쓰에이 데뷔 준비→원더걸스 합류\"…혜림, 힘들었던 과거 고백\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------카테고리[스포츠]--------------------\n",
      " 시즌            \t9\n",
      " 류현진           \t8\n",
      " 선수            \t8\n",
      " 이닝            \t7\n",
      " 연승            \t6\n",
      " 무실점           \t5\n",
      " 손흥민           \t5\n",
      " 현역            \t5\n",
      " 홈런            \t4\n",
      " 토론토           \t4\n",
      " 토트넘           \t4\n",
      " 연속            \t3\n",
      " 맨유            \t3\n",
      " 선두            \t3\n",
      " 출전            \t3\n",
      " 김신욱           \t3\n",
      " 추신수           \t3\n",
      " 타자            \t3\n",
      " 공동            \t3\n",
      " 코로나           \t3\n",
      " 합류            \t3\n",
      " 이적            \t3\n",
      " 레전드           \t3\n",
      " 관왕            \t3\n",
      " 수상            \t3\n",
      " 감독            \t3\n",
      " 우리            \t3\n",
      " 프로야구          \t2\n",
      " 가드            \t2\n",
      " 린츠            \t2\n",
      " 유로파           \t2\n",
      " 강행            \t2\n",
      " 전쟁            \t2\n",
      " 인종차별          \t2\n",
      " 기부            \t2\n",
      " 미우라           \t2\n",
      " 요시            \t2\n",
      " 최고            \t2\n",
      " 재정난           \t2\n",
      " 직원            \t2\n",
      " 해고            \t2\n",
      " 김광현           \t2\n",
      " 선발            \t2\n",
      " 로테이션          \t2\n",
      " 맨시티           \t2\n",
      " 선정            \t2\n",
      " 우뚝            \t2\n",
      " 선물            \t2\n",
      " 올해            \t2\n",
      " 리그            \t2\n",
      "\n",
      " ********** 순위 ************* \n",
      "\n",
      "\t 1순위:시즌\n",
      "\t 2순위:류현진\n",
      "\t 3순위:선수\n",
      "\n",
      " ********** 기사 ************* \n",
      "\n",
      "'홈런 선두' 로하스, 시즌 27호포 폭발…2위와 8개 격차\n",
      "\n",
      "'5이닝 무실점' 류현진, 토론토 유니폼 입고 첫 승 신고\n",
      "\n",
      "추신수, 1회 선두타자 홈런…MLB 현역 선수 중 공동 1위\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "전체 기사 수 :2203\n",
      "---------------카테고리[전체 ]--------------------\n",
      " 코로나           \t154\n",
      " 사망            \t84\n",
      " 폭발            \t80\n",
      " 트럼프           \t80\n",
      " 뉴스            \t76\n",
      " 피해            \t72\n",
      " 서울            \t72\n",
      " 지원            \t70\n",
      " 특별            \t62\n",
      " 베이루트          \t60\n",
      " 주민            \t60\n",
      " 레바논           \t56\n",
      " 수위            \t56\n",
      " 정부            \t54\n",
      " 논란            \t54\n",
      " 영상            \t54\n",
      " 북한            \t52\n",
      " 원피스           \t52\n",
      " 실종            \t52\n",
      " 방류            \t50\n",
      " 호정            \t50\n",
      " 대피            \t48\n",
      " 선박            \t44\n",
      " 미국            \t44\n",
      " 확진            \t42\n",
      " 유착            \t42\n",
      " 공개            \t42\n",
      " 내일            \t42\n",
      " 통제            \t42\n",
      " 주택            \t40\n",
      " 마을            \t40\n",
      " 곳곳            \t38\n",
      " 부동산           \t38\n",
      " 신규            \t38\n",
      " 중국            \t38\n",
      " 지역            \t36\n",
      " 침수            \t36\n",
      " 구조            \t36\n",
      " 침몰            \t34\n",
      " 현장            \t34\n",
      " 도로            \t34\n",
      " 한강            \t34\n",
      " 작업            \t34\n",
      " 통합            \t32\n",
      " 홍수            \t32\n",
      " 의암댐           \t32\n",
      " 참사            \t32\n",
      " 긴급            \t30\n",
      " 윤석열           \t30\n",
      " 의암호           \t30\n",
      "\n",
      " ********** 순위 ************* \n",
      "\n",
      "\t 1순위:코로나\n",
      "\t 2순위:사망\n",
      "\t 3순위:폭발\n",
      "\n",
      " ********** 기사 *************\n",
      "'해외 입국' 주한미군 6명 코로나19 확진 판정\n",
      "\n",
      "수문 빨려 들어간 선박…의암댐서 3척 전복 · 1명 사망\n",
      "\n",
      "외교부 \"베이루트 폭발 재외국민 2명 주택파손…인명피해 없어\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "get_sbs()\n",
    "jtbc_news_list(20200806)\n",
    "get_ytn()\n",
    "MBN()\n",
    "ASIA()\n",
    "\n",
    "################################# 텍스트에 Data 저장된 상태\n",
    "\n",
    "txt_save_list = ['a.txt', 'b.txt', 'c.txt', 'd.txt', 'e.txt', 'f.txt', 'g.txt']\n",
    "\n",
    "txt_file_list = [\n",
    "    'a1.txt', 'a2.txt', 'a3.txt', 'a4.txt', 'a5.txt',\n",
    "    'b1.txt', 'b2.txt', 'b3.txt', 'b4.txt', 'b5.txt' ,\n",
    "    'c1.txt', 'c2.txt', 'c3.txt', 'c4.txt',  'c5.txt' ,\n",
    "    'd1.txt', 'd2.txt', 'd3.txt', 'd4.txt', 'd5.txt' ,\n",
    "    'e1.txt', 'e2.txt', 'e3.txt', 'e4.txt', 'e5.txt' ,\n",
    "    'f1.txt', 'f2.txt', 'f3.txt', 'f4.txt','f5.txt' ,\n",
    "    'g1.txt', 'g2.txt', 'g3.txt', 'g4.txt','g5.txt' \n",
    "]\n",
    "\n",
    "title_name_list=['정치','경제','사회','국제','생활&문화','연예','스포츠']\n",
    "\n",
    "#txt_file_list = [ 'a1.txt', 'a2.txt', 'a3.txt', 'b1.txt', 'b2.txt', 'b3.txt', 'c1.txt', 'c2.txt', 'c3.txt']\n",
    "\n",
    "\n",
    "\n",
    "category_index_point = 0\n",
    "\n",
    "\n",
    "while category_index_point < 7: # 카테고리 탐색\n",
    "    \n",
    "    \n",
    "    s = [] #sbs\n",
    "    d = [] #jtbc\n",
    "    e = [] #ytn\n",
    "    g = [] #mbn\n",
    "    l = [] #asia\n",
    "\n",
    "    f = open(txt_file_list[category_index_point * 5] , 'r') # 0, 5 , 10 , 15,20,25,30\n",
    "    s = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    f = open(txt_file_list[(category_index_point*5) + 1] , 'r') #1,6,11,16,21,26,31\n",
    "    d = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    if((category_index_point * 5) + 2) == 27:\n",
    "        pass\n",
    "    else:\n",
    "        f = open(txt_file_list[(category_index_point*5) + 2] , 'r') #2,7,12,17,22,27,32\n",
    "        e = f.read()\n",
    "        f.close()\n",
    "    \n",
    "    f = open(txt_file_list[(category_index_point*5) + 3] , 'r') #3,8,13,18,23,38,33\n",
    "    g = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    if((category_index_point * 5) + 4) == 34:\n",
    "        pass\n",
    "    else:\n",
    "        f = open(txt_file_list[(category_index_point*5) + 4] , 'r') #4,9,14,19,24,39,34\n",
    "        l = f.read()\n",
    "        f.close()\n",
    "    \n",
    "    \n",
    "    if((category_index_point * 5) + 2) != 27 and ((category_index_point * 5) + 4) != 34:\n",
    "        s = s + d + e + g + l\n",
    "        \n",
    "    elif ((category_index_point * 5) + 2) == 27:\n",
    "        s = s + d + g + l\n",
    "    elif ((category_index_point * 5) + 4) == 34:\n",
    "        s = s + d + g + e\n",
    "        \n",
    "    f = open(txt_save_list[category_index_point], 'w+t')\n",
    "    f.write(s)\n",
    "    f.close()\n",
    "    \n",
    "    if os.path.exists('total.txt'):\n",
    "        f1 = open('total.txt', 'a')\n",
    "        f1.write(s)\n",
    "        f1.close()\n",
    "    else:\n",
    "        f1 = open('total.txt', 'w')\n",
    "        f1.write(s)\n",
    "        f1.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    category_index_point += 1 # 다음 카테고리\n",
    "    \n",
    "category_index_point = 0\n",
    "\n",
    "while category_index_point < 7:\n",
    "    \n",
    "    #### 순위를 찾아내기위한 문장 리스트###\n",
    "    line_list=[]\n",
    "    \n",
    "    f = open(txt_save_list[category_index_point], 'r')\n",
    "    lines = f.read()\n",
    "    line_list = lines.split('\\n')\n",
    "    \n",
    "\n",
    "    nlpy = Twitter()\n",
    "    nouns = nlpy.nouns(lines)\n",
    "    count = Counter(nouns)\n",
    "\n",
    "    tag_count = []\n",
    "    tags = []\n",
    "    \n",
    "\n",
    "    \n",
    "    for n, c in count.most_common(100):\n",
    "        dics = {'tag' : n, 'count' : c}\n",
    "        if len(dics['tag']) >= 2 and len(tags) <= 49:\n",
    "            tag_count.append(dics)\n",
    "            tags.append(dics['tag'])\n",
    "    \n",
    "    #### 순위 3위까지의 리스트#####\n",
    "    rank=[]\n",
    "    \n",
    "    rank.clear()\n",
    "    print('---------------카테고리[{}]--------------------'.format(title_name_list[category_index_point]) )\n",
    "    for idx,tag in enumerate(tag_count):    \n",
    "     #### 순위 3위까지의 리스트 뽑아내기 && 기사 뽑아내기#####\n",
    "        if(idx == 0 or idx == 1 or idx == 2 ):\n",
    "            rank.append(tag['tag'])   \n",
    "        print(\" {:<14}\".format(tag['tag']), end='\\t')\n",
    "        print(\"{}\".format(tag['count']))   \n",
    "        \n",
    "            \n",
    "            \n",
    "    print(\"\\n ********** 순위 ************* \\n\")  \n",
    "    print('\\t 1순위:{}'.format(rank[0]))\n",
    "    print('\\t 2순위:{}'.format(rank[1]))\n",
    "    print('\\t 3순위:{}'.format(rank[2]))  \n",
    "    \n",
    "    rank_li=[]\n",
    "    rank_li.clear() \n",
    "    \n",
    "    temp=0\n",
    "    for line_li in line_list:\n",
    "        if rank[0] in line_li:\n",
    "            temp+=1\n",
    "            if temp == 2:\n",
    "                break\n",
    "            rank_li.append(line_li+'\\n')\n",
    "\n",
    "    temp=0\n",
    "    for line_li in line_list:\n",
    "        if rank[1] in line_li:\n",
    "            temp+=1\n",
    "            if temp == 2:\n",
    "                break\n",
    "            rank_li.append(line_li+'\\n')\n",
    "    temp=0\n",
    "    for line_li in line_list:\n",
    "        if rank[2] in line_li:\n",
    "            temp+=1\n",
    "            if temp == 2:\n",
    "                break\n",
    "            rank_li.append(line_li+'\\n')  \n",
    "                \n",
    "    print(\"\\n ********** 기사 ************* \\n\")\n",
    "    print(rank_li[0])\n",
    "    print(rank_li[1])\n",
    "    print(rank_li[2])\n",
    "\n",
    "\n",
    "                     \n",
    "        \n",
    "    new_list = []\n",
    "    \n",
    "    for tag in tag_count:\n",
    "        a = tag['tag']\n",
    "        b = tag['count']\n",
    "        c = (a, b)\n",
    "        new_list.append(c)\n",
    "        \n",
    "        \n",
    "    alice_mask = np.array(Image.open(\"cloud.png\"))\n",
    "    font_path = 'C:/Windows/Fonts/malgun.ttf';\n",
    "    wc = WordCloud(font_path = font_path, background_color = 'white', \n",
    "        width=800, height=600, mask = alice_mask)\n",
    "    cloud = wc.generate_from_frequencies(dict(new_list))\n",
    "    plt.figure(figsize=(10,8), dpi=200)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(cloud)\n",
    "    \n",
    "    category_index_point += 1\n",
    "    \n",
    "    \n",
    "    print('\\n' * 10)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "f3 = open('total.txt', 'r')\n",
    "\n",
    "lines = f3.readline()\n",
    "news_topic_count = 1\n",
    "\n",
    "line_list.clear()\n",
    "while lines:\n",
    "    \n",
    "    lines = f3.readline()\n",
    "    news_topic_count += 1\n",
    "\n",
    "\n",
    "    \n",
    "print('전체 기사 수 :{}'.format(news_topic_count))\n",
    "\n",
    "f3.close()\n",
    "    \n",
    "\n",
    "f = open('total.txt', 'r')\n",
    "lines = f.read()\n",
    "#### 순위를 찾아내기위한 문장 리스트###\n",
    "line_list = lines.split('\\n')\n",
    "f.close()\n",
    "\n",
    "nlpy = Twitter()\n",
    "nouns = nlpy.nouns(lines)\n",
    "count = Counter(nouns)\n",
    "\n",
    "tag_count = []\n",
    "tags = []\n",
    "\n",
    "\n",
    "\n",
    "for n, c in count.most_common(100):\n",
    "    dics = {'tag' : n, 'count' : c}\n",
    "    if len(dics['tag']) >= 2 and len(tags) <= 49:\n",
    "        tag_count.append(dics)\n",
    "        tags.append(dics['tag'])\n",
    "        \n",
    "rank=[]\n",
    "    \n",
    "rank.clear()\n",
    "print('---------------카테고리[전체 ]--------------------' )\n",
    "for idx,tag in enumerate(tag_count):\n",
    " #### 순위 3위까지의 리스트 뽑아내기 && 기사 뽑아내기#####\n",
    "    if(idx == 0 or idx == 1 or idx == 2 ):\n",
    "        rank.append(tag['tag'])\n",
    "        \n",
    "    print(\" {:<14}\".format(tag['tag']), end='\\t')\n",
    "    print(\"{}\".format(tag['count']))   \n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n ********** 순위 ************* \\n\")  \n",
    "print('\\t 1순위:{}'.format(rank[0]))\n",
    "print('\\t 2순위:{}'.format(rank[1]))\n",
    "print('\\t 3순위:{}'.format(rank[2]))  \n",
    "\n",
    "rank_li.clear() \n",
    "\n",
    "\n",
    "temp=0\n",
    "for line_li in line_list:\n",
    "    if rank[0] in line_li:\n",
    "        temp+=1\n",
    "        if temp == 2:\n",
    "            break\n",
    "        rank_li.append(line_li+'\\n')\n",
    "        \n",
    "temp=0\n",
    "for line_li in line_list:\n",
    "    if rank[1] in line_li:\n",
    "        temp+=1\n",
    "        if temp == 2:\n",
    "            break\n",
    "        rank_li.append(line_li+'\\n')\n",
    "temp=0\n",
    "for line_li in line_list:\n",
    "    if rank[2] in line_li:\n",
    "        temp+=1\n",
    "        if temp == 2:\n",
    "            break\n",
    "        rank_li.append(line_li+'\\n')        \n",
    "            \n",
    "print(\"\\n ********** 기사 *************\")\n",
    "print(rank_li[0])\n",
    "print(rank_li[1])\n",
    "print(rank_li[2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_list = []\n",
    "\n",
    "for tag in tag_count:\n",
    "    a = tag['tag']\n",
    "    b = tag['count']\n",
    "    c = (a, b)\n",
    "    new_list.append(c)\n",
    "\n",
    "\n",
    "alice_mask = np.array(Image.open(\"cloud.png\"))\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf';\n",
    "wc = WordCloud(font_path = font_path, background_color = 'white', \n",
    "    width=800, height=600, mask = alice_mask)\n",
    "cloud = wc.generate_from_frequencies(dict(new_list))\n",
    "plt.figure(figsize=(10,8), dpi = 200)\n",
    "plt.axis('off')\n",
    "plt.imshow(cloud)\n",
    "\n",
    "    \n",
    "os.remove('total.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
