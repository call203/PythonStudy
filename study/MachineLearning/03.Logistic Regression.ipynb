{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    참 거짓을 판단하는 알고리즘\n",
    "    1. '참 거짓 미리 판단 장치'를 만들어 주어진 입력 값의 특징을 추출함.\n",
    "    2. 이를 저장해서 '모델'을 만듬\n",
    "    3. 누군가 비슷한 질문을 하면 지금까지 만들어 높은 모델을 꺼내 답 \n",
    "    \n",
    "    \n",
    "    그래프 모양이 s자 형태  --> 시그모이드 함수\n",
    "    \n",
    "    \n",
    "    *오차 구하는 법*\n",
    "    평균제곱근 오차는 사용하지 않음.(gobal이 아닌 Local 미니멈을 구할 위험이 있어서)\n",
    "    \n",
    "    *특징*\n",
    "    -y값이 0 과 1사이라는것.\n",
    "    -따라서 실제값이 1일때 예측값이 0에 가까워져야하고 실제값이 0일때 예측값이 1에 가까워져야한다.\n",
    "    -실제값이 1일때 예측값이 1이라면 코스트 함수의 값은 0에 가까운것.\n",
    "    \n",
    "    weight:기울기, bias:절편\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0.000000, loss:1.2676,  a=0.1849, y절편=-0.4334\n",
      "Epoch:6000.000000, loss:0.0152,  a=-2.9211, y절편=20.2983\n",
      "Epoch:12000.000000, loss:0.0081,  a=-3.5638, y절편=24.8011\n",
      "Epoch:18000.000000, loss:0.0055,  a=-3.9557, y절편=27.5464\n",
      "Epoch:24000.000000, loss:0.0041,  a=-4.2380, y절편=29.5232\n",
      "Epoch:30000.000000, loss:0.0033,  a=-4.4586, y절편=31.0676\n",
      "Epoch:36000.000000, loss:0.0028,  a=-4.6396, y절편=32.3346\n",
      "Epoch:42000.000000, loss:0.0024,  a=-4.7930, y절편=33.4087\n",
      "Epoch:48000.000000, loss:0.0021,  a=-4.9261, y절편=34.3406\n",
      "Epoch:54000.000000, loss:0.0019,  a=-5.0436, y절편=35.1636\n",
      "Epoch:60000.000000, loss:0.0017,  a=-5.1489, y절편=35.9005\n",
      "[3.88397689e-05]\n",
      "[0.53537991]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "#데이터 값\n",
    "data=[[2,0],[4,0],[6,0],[8,1],[10,1],[12,1],[14,1]]\n",
    "x_data =[x_row[0] for x_row in data]\n",
    "y_data =[y_row[1] for y_row in data]\n",
    "test_data = [5,7,13]\n",
    "\n",
    "#a와 b의 값을 임의로 정함\n",
    "#값의 범위는 지정해 주지 않음\n",
    "a = tf.Variable(tf.random_normal([1],dtype=tf.float64,seed=0))\n",
    "b = tf.Variable(tf.random_normal([1],dtype=tf.float64,seed=0))\n",
    "\n",
    "\n",
    "#y 시그모이드 함수의 방정식을 세운다.\n",
    "y = 1/(1 + np.e**(a*x_data + b))\n",
    "\n",
    "\n",
    "#loss를 구하는 함수\n",
    "loss = -tf.reduce_mean(np.array(y_data)* tf.log(y) + (1- np.array(y_data)) * tf.log(1-y))\n",
    "\n",
    "\n",
    "#학습률 값\n",
    "learning_rate = 0.5\n",
    "\n",
    "#loass를 최소로 하는 값 찾기\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "#학습\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(60001):\n",
    "        sess.run(gradient_decent) \n",
    "        \n",
    "        if step % 6000 == 0:\n",
    "            print(\"Epoch:%f, loss:%.4f,  a=%.4f, y절편=%.4f\"% (step, sess.run(loss),sess.run(a),sess.run(b)))\n",
    "            if(step ==60000):\n",
    "                a = sess.run(a)\n",
    "                b = sess.run(b)\n",
    "                for i in test_data:\n",
    "                    print( 1/(1 + np.e**(a*i + b)))\n",
    "\n",
    "                    \n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1.0,2.0,3.0]])\n",
    "w = tf.constant([[2.0],[2.0],[2.0]])\n",
    "y = tf.matmul(x,w)\n",
    "print(x.shape)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "result = sess.run(y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([[1.,2.,3.]],dtype=tf.float32)\n",
    "w = tf.Variable([[2.],[2.],[2.]],dtype=tf.float32)\n",
    "y = tf.matmul(x,w)\n",
    "print(x.shape)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "result = sess.run(y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]\n",
      " [12.]\n",
      " [18.]]\n"
     ]
    }
   ],
   "source": [
    "input_data = [[1.,2.,3.],[1.,2.,3.],[2.,3.,4.]]\n",
    "x = tf.placeholder(dtype=tf.float32,shape=[None,3])\n",
    "w = tf.Variable([[2.],[2.],[2.]],dtype=tf.float32)\n",
    "y = tf.matmul(x,w)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "result = sess.run(y,feed_dict={x:input_data})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 브로드 캐스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[10.]\n",
      " [16.]]\n"
     ]
    }
   ],
   "source": [
    "input_data=[[1,1,1],[2,2,2]]\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[2,3])\n",
    "w = tf.Variable([[2],[2],[2]], dtype=tf.float32)\n",
    "b =tf.Variable([[4]], dtype=tf.float32)\n",
    "\n",
    "y = tf.matmul(x,w) + b\n",
    "print(x.shape)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "result = sess.run(y,feed_dict={x:input_data})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러 입력값을 갖는 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=300, al=0.8955, a2=-0.7045, b=-2.2229, loss=0.2801\n",
      "step=600, al=0.8778, a2=-0.4010, b=-3.7343, loss=0.1996\n",
      "step=900, al=0.7770, a2=-0.0531, b=-4.8271, loss=0.1552\n",
      "step=1200, al=0.6652, a2=0.2685, b=-5.6893, loss=0.1264\n",
      "step=1500, al=0.5601, a2=0.5532, b=-6.4025, loss=0.1063\n",
      "step=1800, al=0.4658, a2=0.8032, b=-7.0109, loss=0.0916\n",
      "step=2100, al=0.3826, a2=1.0229, b=-7.5416, loss=0.0803\n",
      "step=2400, al=0.3093, a2=1.2172, b=-8.0123, loss=0.0715\n",
      "step=2700, al=0.2447, a2=1.3903, b=-8.4352, loss=0.0644\n",
      "step=3000, al=0.1874, a2=1.5456, b=-8.8192, loss=0.0585\n",
      "predicted= [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-f97543b8ee7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predicted=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# 다른값 테스트\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mp_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"check predicted=\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"check hypothesis=\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "x_data = np.array([[2,3],[4,3],[6,4],[8,6],[10,7],[12,8],[14,9]])\n",
    "y_data = np.array([0,0,0,1,1,1,1]).reshape(7,1)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float64, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float64, shape=[None, 1])\n",
    "\n",
    "a = tf.Variable(tf.random_uniform([2,1], dtype=tf.float64))\n",
    "b = tf.Variable(tf.random_uniform([1], dtype=tf.float64))\n",
    "\n",
    "y = tf.sigmoid(tf.matmul(X,a)+b)\n",
    "\n",
    "loss = -tf.reduce_mean(Y* tf.log(y) + (1-Y) * tf.log(1-y))\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "predicted = tf.cast(y >0.5,dtype=tf.float64)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y), dtype=tf.float64))\n",
    "\n",
    "\n",
    "#학습\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(3001):\n",
    "        a_,b_,loss_,_=sess.run([a,b,loss,gradient_descent], feed_dict={X:x_data, Y:y_data})\n",
    "        if(step +1) % 300 == 0:             \n",
    "            print(\"step=%d, al=%.4f, a2=%.4f, b=%.4f, loss=%.4f\" %(step+1, a_[0], a_[1],b_,loss_) )\n",
    "            \n",
    "    print(\"predicted=\", sess.run(predicted, feed_dict={X:x_data}))\n",
    "    # 다른값 테스트\n",
    "    p_val, h_val = sess.run([predicted,y],feed_dict={[[1,5],[10,5],[4,5]]})\n",
    "    print(\"check predicted=\",p_val)\n",
    "    print(\"check hypothesis=\",h_val)\n",
    "    #정확도 측정\n",
    "    h,c,a=sess.run([y,predicted,accuracy], feed_dict ={X:x_data, Y:y_data})\n",
    "    prin(\"\\nHypothesis:\",h,\"\\nDorrect(y): \",c,\"\\n Accuracy:\",a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
