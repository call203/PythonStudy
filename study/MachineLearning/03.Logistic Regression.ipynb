{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    참 거짓을 판단하는 알고리즘\n",
    "    1. '참 거짓 미리 판단 장치'를 만들어 주어진 입력 값의 특징을 추출함.\n",
    "    2. 이를 저장해서 '모델'을 만듬\n",
    "    3. 누군가 비슷한 질문을 하면 지금까지 만들어 높은 모델을 꺼내 답 \n",
    "    \n",
    "    \n",
    "    그래프 모양이 s자 형태  --> 시그모이드 함수\n",
    "    \n",
    "    \n",
    "    *오차 구하는 법*\n",
    "    평균제곱근 오차는 사용하지 않음.(gobal이 아닌 Local 미니멈을 구할 위험이 있어서)\n",
    "    \n",
    "    *특징*\n",
    "    -y값이 0 과 1사이라는것.\n",
    "    -따라서 실제값이 1일때 예측값이 0에 가까워져야하고 실제값이 0일때 예측값이 1에 가까워져야한다.\n",
    "    -실제값이 1일때 예측값이 1이라면 코스트 함수의 값은 0에 가까운것.\n",
    "    \n",
    "    weight:기울기, bias:절편\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0.000000, loss:1.2676,  a=0.1849, y절편=-0.4334\n",
      "Epoch:6000.000000, loss:0.0152,  a=-2.9211, y절편=20.2983\n",
      "Epoch:12000.000000, loss:0.0081,  a=-3.5638, y절편=24.8011\n",
      "Epoch:18000.000000, loss:0.0055,  a=-3.9557, y절편=27.5464\n",
      "Epoch:24000.000000, loss:0.0041,  a=-4.2380, y절편=29.5232\n",
      "Epoch:30000.000000, loss:0.0033,  a=-4.4586, y절편=31.0676\n",
      "Epoch:36000.000000, loss:0.0028,  a=-4.6396, y절편=32.3346\n",
      "Epoch:42000.000000, loss:0.0024,  a=-4.7930, y절편=33.4087\n",
      "Epoch:48000.000000, loss:0.0021,  a=-4.9261, y절편=34.3406\n",
      "Epoch:54000.000000, loss:0.0019,  a=-5.0436, y절편=35.1636\n",
      "Epoch:60000.000000, loss:0.0017,  a=-5.1489, y절편=35.9005\n",
      "[3.88397689e-05]\n",
      "[0.53537991]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "#데이터 값\n",
    "data=[[2,0],[4,0],[6,0],[8,1],[10,1],[12,1],[14,1]]\n",
    "x_data =[x_row[0] for x_row in data]\n",
    "y_data =[y_row[1] for y_row in data]\n",
    "test_data = [5,7,13]\n",
    "\n",
    "#a와 b의 값을 임의로 정함\n",
    "#값의 범위는 지정해 주지 않음\n",
    "a = tf.Variable(tf.random_normal([1],dtype=tf.float64,seed=0))\n",
    "b = tf.Variable(tf.random_normal([1],dtype=tf.float64,seed=0))\n",
    "\n",
    "\n",
    "#y 시그모이드 함수의 방정식을 세운다.\n",
    "y = 1/(1 + np.e**(a*x_data + b))\n",
    "\n",
    "\n",
    "#loss를 구하는 함수\n",
    "loss = -tf.reduce_mean(np.array(y_data)* tf.log(y) + (1- np.array(y_data)) * tf.log(1-y))\n",
    "\n",
    "\n",
    "#학습률 값\n",
    "learning_rate = 0.5\n",
    "\n",
    "#loass를 최소로 하는 값 찾기\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "#학습\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(60001):\n",
    "        sess.run(gradient_decent) \n",
    "        \n",
    "        if step % 6000 == 0:\n",
    "            print(\"Epoch:%f, loss:%.4f,  a=%.4f, y절편=%.4f\"% (step, sess.run(loss),sess.run(a),sess.run(b)))\n",
    "            if(step ==60000):\n",
    "                a = sess.run(a)\n",
    "                b = sess.run(b)\n",
    "                for i in test_data:\n",
    "                    print( 1/(1 + np.e**(a*i + b)))\n",
    "\n",
    "                    \n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1.0,2.0,3.0]])\n",
    "w = tf.constant([[2.0],[2.0],[2.0]])\n",
    "y = tf.matmul(x,w)\n",
    "print(x.shape)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "result = sess.run(y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([[1.,2.,3.]],dtype=tf.float32)\n",
    "w = tf.Variable([[2.],[2.],[2.]],dtype=tf.float32)\n",
    "y = tf.matmul(x,w)\n",
    "print(x.shape)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "result = sess.run(y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]\n",
      " [12.]\n",
      " [18.]]\n"
     ]
    }
   ],
   "source": [
    "input_data = [[1.,2.,3.],[1.,2.,3.],[2.,3.,4.]]\n",
    "x = tf.placeholder(dtype=tf.float32,shape=[None,3])\n",
    "w = tf.Variable([[2.],[2.],[2.]],dtype=tf.float32)\n",
    "y = tf.matmul(x,w)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "result = sess.run(y,feed_dict={x:input_data})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 브로드 캐스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[10.]\n",
      " [16.]]\n"
     ]
    }
   ],
   "source": [
    "input_data=[[1,1,1],[2,2,2]]\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[2,3])\n",
    "w = tf.Variable([[2],[2],[2]], dtype=tf.float32)\n",
    "b =tf.Variable([[4]], dtype=tf.float32)\n",
    "\n",
    "y = tf.matmul(x,w) + b\n",
    "print(x.shape)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "result = sess.run(y,feed_dict={x:input_data})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러 입력값을 갖는 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=300, al=0.9453, a2=-0.8026, b=-2.0682, loss=0.2904\n",
      "step=600, al=0.9183, a2=-0.4800, b=-3.6161, loss=0.2057\n",
      "step=900, al=0.8096, a2=-0.1170, b=-4.7318, loss=0.1591\n",
      "step=1200, al=0.6916, a2=0.2163, b=-5.6096, loss=0.1291\n",
      "step=1500, al=0.5815, a2=0.5100, b=-6.3340, loss=0.1083\n",
      "step=1800, al=0.4834, a2=0.7670, b=-6.9510, loss=0.0930\n",
      "step=2100, al=0.3971, a2=0.9922, b=-7.4883, loss=0.0814\n",
      "step=2400, al=0.3215, a2=1.1908, b=-7.9642, loss=0.0724\n",
      "step=2700, al=0.2550, a2=1.3673, b=-8.3915, loss=0.0651\n",
      "step=3000, al=0.1962, a2=1.5254, b=-8.7791, loss=0.0591\n",
      "predicted= [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "check predicted= [[0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "check hypothesis= [[0.27793754]\n",
      " [0.69203411]\n",
      " [0.40936411]]\n",
      "\n",
      "Hypothesis: [[0.02165754]\n",
      " [0.03172454]\n",
      " [0.18236139]\n",
      " [0.87473413]\n",
      " [0.97939654]\n",
      " [0.99691918]\n",
      " [0.99954623]] \n",
      "Correct(y):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      " Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "x_data = np.array([[2,3],[4,3],[6,4],[8,6],[10,7],[12,8],[14,9]])\n",
    "y_data = np.array([0,0,0,1,1,1,1]).reshape(7,1)\n",
    "\n",
    "X = tf.placeholder(tf.float64, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float64, shape=[None, 1])\n",
    "\n",
    "a = tf.Variable(tf.random_uniform([2,1], dtype=tf.float64))\n",
    "b = tf.Variable(tf.random_uniform([1], dtype=tf.float64))\n",
    "\n",
    "y = tf.sigmoid(tf.matmul(X,a)+b)\n",
    "\n",
    "loss = -tf.reduce_mean(Y* tf.log(y) + (1-Y) * tf.log(1-y))\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "predicted = tf.cast(y >0.5,dtype=tf.float64)\n",
    "# reduce_mean:배열의 평균을 구함.   cast: 실제값과 예측값이 같은지 \n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y), dtype=tf.float64)) \n",
    "\n",
    "\n",
    "#학습\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(3001):\n",
    "        a_,b_,loss_,_=sess.run([a,b,loss,gradient_descent], feed_dict={X:x_data, Y:y_data})\n",
    "        if(step +1) % 300 == 0:             \n",
    "            print(\"step=%d, al=%.4f, a2=%.4f, b=%.4f, loss=%.4f\" %(step+1, a_[0], a_[1],b_,loss_) )\n",
    "            \n",
    "    print(\"predicted=\", sess.run(predicted, feed_dict={X:x_data}))\n",
    "    # 다른값 테스트\n",
    "    p_val, h_val = sess.run([predicted, y], feed_dict={X:[ [1, 5], [10, 5], [4, 5] ]} )\n",
    "    print(\"check predicted=\",p_val)\n",
    "    print(\"check hypothesis=\",h_val)\n",
    "    #정확도 측정\n",
    "    h,c,a=sess.run([y,predicted,accuracy], feed_dict ={X:x_data, Y:y_data})\n",
    "    print(\"\\nHypothesis:\",h,\"\\nCorrect(y): \",c,\"\\n Accuracy:\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 당뇨병 데이터 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=200, W1=-0.3402, W2=-1.1976, W3=0.2024,W4=-0.4775,W5=0.0204,W6=0.2459,W7=-0.3661,W8=0.0985, b=0.4883, loss=0.5625\n",
      "step=400, W1=-0.6129, W2=-1.9216, W3=0.0157,W4=-0.6264,W5=-0.1591,W6=-0.1881,W7=-0.4849,W8=-0.0030, b=0.3380, loss=0.5148\n",
      "step=600, W1=-0.7388, W2=-2.3680, W3=-0.0675,W4=-0.7002,W5=-0.2268,W6=-0.5134,W7=-0.6030,W8=-0.0262, b=0.2802, loss=0.4967\n",
      "step=800, W1=-0.8021, W2=-2.6691, W3=-0.1029,W4=-0.7391,W5=-0.2523,W6=-0.7715,W7=-0.7007,W8=-0.0249, b=0.2552, loss=0.4878\n",
      "step=1000, W1=-0.8364, W2=-2.8831, W3=-0.1130,W4=-0.7593,W5=-0.2610,W6=-0.9835,W7=-0.7773,W8=-0.0178, b=0.2431, loss=0.4828\n",
      "step=1200, W1=-0.8561, W2=-3.0405, W3=-0.1087,W4=-0.7686,W5=-0.2631,W6=-1.1618,W7=-0.8360,W8=-0.0110, b=0.2364, loss=0.4798\n",
      "step=1400, W1=-0.8681, W2=-3.1589, W3=-0.0956,W4=-0.7710,W5=-0.2630,W6=-1.3142,W7=-0.8806,W8=-0.0066, b=0.2317, loss=0.4778\n",
      "step=1600, W1=-0.8757, W2=-3.2494, W3=-0.0771,W4=-0.7690,W5=-0.2626,W6=-1.4462,W7=-0.9142,W8=-0.0047, b=0.2279, loss=0.4764\n",
      "step=1800, W1=-0.8807, W2=-3.3192, W3=-0.0553,W4=-0.7640,W5=-0.2625,W6=-1.5615,W7=-0.9392,W8=-0.0050, b=0.2242, loss=0.4755\n",
      "step=2000, W1=-0.8843, W2=-3.3736, W3=-0.0316,W4=-0.7569,W5=-0.2631,W6=-1.6633,W7=-0.9578,W8=-0.0070, b=0.2206, loss=0.4747\n",
      "step=2200, W1=-0.8867, W2=-3.4163, W3=-0.0069,W4=-0.7485,W5=-0.2645,W6=-1.7535,W7=-0.9715,W8=-0.0103, b=0.2168, loss=0.4742\n",
      "step=2400, W1=-0.8886, W2=-3.4499, W3=0.0182,W4=-0.7392,W5=-0.2664,W6=-1.8341,W7=-0.9814,W8=-0.0145, b=0.2130, loss=0.4738\n",
      "step=2600, W1=-0.8900, W2=-3.4764, W3=0.0432,W4=-0.7293,W5=-0.2689,W6=-1.9064,W7=-0.9885,W8=-0.0192, b=0.2091, loss=0.4734\n",
      "step=2800, W1=-0.8910, W2=-3.4975, W3=0.0678,W4=-0.7191,W5=-0.2717,W6=-1.9715,W7=-0.9934,W8=-0.0243, b=0.2052, loss=0.4732\n",
      "step=3000, W1=-0.8918, W2=-3.5143, W3=0.0918,W4=-0.7087,W5=-0.2749,W6=-2.0303,W7=-0.9967,W8=-0.0295, b=0.2013, loss=0.4729\n",
      "step=3200, W1=-0.8925, W2=-3.5277, W3=0.1149,W4=-0.6984,W5=-0.2784,W6=-2.0836,W7=-0.9988,W8=-0.0348, b=0.1975, loss=0.4728\n",
      "step=3400, W1=-0.8931, W2=-3.5383, W3=0.1372,W4=-0.6883,W5=-0.2820,W6=-2.1321,W7=-1.0000,W8=-0.0401, b=0.1937, loss=0.4726\n",
      "step=3600, W1=-0.8936, W2=-3.5469, W3=0.1585,W4=-0.6783,W5=-0.2856,W6=-2.1762,W7=-1.0006,W8=-0.0452, b=0.1900, loss=0.4725\n",
      "step=3800, W1=-0.8940, W2=-3.5538, W3=0.1788,W4=-0.6686,W5=-0.2893,W6=-2.2166,W7=-1.0007,W8=-0.0501, b=0.1864, loss=0.4724\n",
      "step=4000, W1=-0.8943, W2=-3.5593, W3=0.1980,W4=-0.6593,W5=-0.2930,W6=-2.2535,W7=-1.0004,W8=-0.0549, b=0.1829, loss=0.4723\n",
      "step=4200, W1=-0.8947, W2=-3.5638, W3=0.2163,W4=-0.6503,W5=-0.2966,W6=-2.2873,W7=-1.0000,W8=-0.0594, b=0.1796, loss=0.4722\n",
      "step=4400, W1=-0.8950, W2=-3.5674, W3=0.2335,W4=-0.6416,W5=-0.3002,W6=-2.3184,W7=-0.9993,W8=-0.0637, b=0.1763, loss=0.4721\n",
      "step=4600, W1=-0.8953, W2=-3.5704, W3=0.2498,W4=-0.6334,W5=-0.3037,W6=-2.3469,W7=-0.9986,W8=-0.0678, b=0.1732, loss=0.4721\n",
      "step=4800, W1=-0.8956, W2=-3.5728, W3=0.2651,W4=-0.6255,W5=-0.3070,W6=-2.3732,W7=-0.9979,W8=-0.0716, b=0.1702, loss=0.4720\n",
      "step=5000, W1=-0.8959, W2=-3.5747, W3=0.2796,W4=-0.6180,W5=-0.3103,W6=-2.3974,W7=-0.9971,W8=-0.0752, b=0.1674, loss=0.4720\n",
      "step=5200, W1=-0.8961, W2=-3.5764, W3=0.2931,W4=-0.6110,W5=-0.3134,W6=-2.4197,W7=-0.9964,W8=-0.0786, b=0.1647, loss=0.4719\n",
      "step=5400, W1=-0.8964, W2=-3.5777, W3=0.3058,W4=-0.6043,W5=-0.3164,W6=-2.4403,W7=-0.9956,W8=-0.0818, b=0.1621, loss=0.4719\n",
      "step=5600, W1=-0.8967, W2=-3.5788, W3=0.3177,W4=-0.5979,W5=-0.3192,W6=-2.4594,W7=-0.9950,W8=-0.0848, b=0.1597, loss=0.4719\n",
      "step=5800, W1=-0.8969, W2=-3.5798, W3=0.3289,W4=-0.5920,W5=-0.3219,W6=-2.4770,W7=-0.9943,W8=-0.0875, b=0.1574, loss=0.4718\n",
      "step=6000, W1=-0.8971, W2=-3.5806, W3=0.3394,W4=-0.5863,W5=-0.3245,W6=-2.4932,W7=-0.9937,W8=-0.0901, b=0.1552, loss=0.4718\n",
      "step=6200, W1=-0.8974, W2=-3.5813, W3=0.3492,W4=-0.5810,W5=-0.3269,W6=-2.5083,W7=-0.9931,W8=-0.0926, b=0.1531, loss=0.4718\n",
      "step=6400, W1=-0.8976, W2=-3.5818, W3=0.3583,W4=-0.5761,W5=-0.3292,W6=-2.5223,W7=-0.9926,W8=-0.0948, b=0.1511, loss=0.4718\n",
      "step=6600, W1=-0.8978, W2=-3.5823, W3=0.3669,W4=-0.5714,W5=-0.3314,W6=-2.5352,W7=-0.9921,W8=-0.0969, b=0.1493, loss=0.4718\n",
      "step=6800, W1=-0.8980, W2=-3.5828, W3=0.3749,W4=-0.5670,W5=-0.3335,W6=-2.5472,W7=-0.9917,W8=-0.0989, b=0.1475, loss=0.4717\n",
      "step=7000, W1=-0.8983, W2=-3.5832, W3=0.3824,W4=-0.5629,W5=-0.3354,W6=-2.5584,W7=-0.9913,W8=-0.1007, b=0.1459, loss=0.4717\n",
      "step=7200, W1=-0.8985, W2=-3.5835, W3=0.3893,W4=-0.5590,W5=-0.3372,W6=-2.5687,W7=-0.9910,W8=-0.1024, b=0.1443, loss=0.4717\n",
      "step=7400, W1=-0.8986, W2=-3.5838, W3=0.3959,W4=-0.5554,W5=-0.3390,W6=-2.5783,W7=-0.9906,W8=-0.1040, b=0.1428, loss=0.4717\n",
      "step=7600, W1=-0.8988, W2=-3.5841, W3=0.4019,W4=-0.5520,W5=-0.3406,W6=-2.5872,W7=-0.9904,W8=-0.1055, b=0.1415, loss=0.4717\n",
      "step=7800, W1=-0.8990, W2=-3.5843, W3=0.4076,W4=-0.5489,W5=-0.3421,W6=-2.5954,W7=-0.9901,W8=-0.1069, b=0.1402, loss=0.4717\n",
      "step=8000, W1=-0.8992, W2=-3.5846, W3=0.4129,W4=-0.5459,W5=-0.3435,W6=-2.6031,W7=-0.9899,W8=-0.1082, b=0.1389, loss=0.4717\n",
      "step=8200, W1=-0.8993, W2=-3.5848, W3=0.4179,W4=-0.5432,W5=-0.3448,W6=-2.6102,W7=-0.9897,W8=-0.1094, b=0.1378, loss=0.4717\n",
      "step=8400, W1=-0.8995, W2=-3.5850, W3=0.4225,W4=-0.5406,W5=-0.3461,W6=-2.6169,W7=-0.9895,W8=-0.1105, b=0.1367, loss=0.4717\n",
      "step=8600, W1=-0.8996, W2=-3.5851, W3=0.4268,W4=-0.5382,W5=-0.3473,W6=-2.6230,W7=-0.9893,W8=-0.1115, b=0.1357, loss=0.4717\n",
      "step=8800, W1=-0.8998, W2=-3.5853, W3=0.4308,W4=-0.5359,W5=-0.3484,W6=-2.6288,W7=-0.9892,W8=-0.1125, b=0.1347, loss=0.4717\n",
      "step=9000, W1=-0.8999, W2=-3.5854, W3=0.4346,W4=-0.5338,W5=-0.3494,W6=-2.6341,W7=-0.9891,W8=-0.1134, b=0.1339, loss=0.4717\n",
      "step=9200, W1=-0.9000, W2=-3.5856, W3=0.4381,W4=-0.5319,W5=-0.3503,W6=-2.6390,W7=-0.9889,W8=-0.1142, b=0.1330, loss=0.4717\n",
      "step=9400, W1=-0.9001, W2=-3.5857, W3=0.4414,W4=-0.5301,W5=-0.3512,W6=-2.6437,W7=-0.9888,W8=-0.1150, b=0.1322, loss=0.4717\n",
      "step=9600, W1=-0.9003, W2=-3.5858, W3=0.4444,W4=-0.5284,W5=-0.3521,W6=-2.6479,W7=-0.9888,W8=-0.1157, b=0.1315, loss=0.4717\n",
      "step=9800, W1=-0.9004, W2=-3.5859, W3=0.4472,W4=-0.5268,W5=-0.3529,W6=-2.6519,W7=-0.9887,W8=-0.1164, b=0.1308, loss=0.4717\n",
      "step=10000, W1=-0.9005, W2=-3.5860, W3=0.4499,W4=-0.5253,W5=-0.3536,W6=-2.6556,W7=-0.9886,W8=-0.1170, b=0.1302, loss=0.4717\n",
      "\n",
      "Hypothesis: [[0.35596866]\n",
      " [0.95639393]\n",
      " [0.19285956]\n",
      " [0.96235106]\n",
      " [0.07095533]\n",
      " [0.83175731]\n",
      " [0.95332508]\n",
      " [0.57475253]\n",
      " [0.17847818]\n",
      " [0.5912482 ]\n",
      " [0.75243588]\n",
      " [0.11042002]\n",
      " [0.27147168]\n",
      " [0.19460312]\n",
      " [0.78108804]\n",
      " [0.38191152]\n",
      " [0.7933695 ]\n",
      " [0.7639691 ]\n",
      " [0.81929315]\n",
      " [0.5751317 ]\n",
      " [0.7221479 ]\n",
      " [0.05969478]\n",
      " [0.72047392]\n",
      " [0.67694516]\n",
      " [0.28769839]\n",
      " [0.96194899]\n",
      " [0.61689891]\n",
      " [0.70599293]\n",
      " [0.7059179 ]\n",
      " [0.39824259]\n",
      " [0.96943751]\n",
      " [0.95072881]\n",
      " [0.64534265]\n",
      " [0.87063881]\n",
      " [0.34941616]\n",
      " [0.68876734]\n",
      " [0.83858157]\n",
      " [0.51526257]\n",
      " [0.32658212]\n",
      " [0.32004693]\n",
      " [0.91248097]\n",
      " [0.09808557]\n",
      " [0.3781873 ]\n",
      " [0.02334092]\n",
      " [0.54507777]\n",
      " [0.96314552]\n",
      " [0.68745736]\n",
      " [0.72970889]\n",
      " [0.97084073]\n",
      " [0.94917039]\n",
      " [0.95934007]\n",
      " [0.18667301]\n",
      " [0.27799357]\n",
      " [0.98012006]\n",
      " [0.11390903]\n",
      " [0.43364553]\n",
      " [0.08605315]\n",
      " [0.66181932]\n",
      " [0.89799887]\n",
      " [0.49542117]\n",
      " [0.97817751]\n",
      " [0.7164247 ]\n",
      " [0.67578704]\n",
      " [0.89761137]\n",
      " [0.65932781]\n",
      " [0.57690865]\n",
      " [0.97835341]\n",
      " [0.7257885 ]\n",
      " [0.86906109]\n",
      " [0.66523695]\n",
      " [0.21924981]\n",
      " [0.73399532]\n",
      " [0.94929358]\n",
      " [0.94743837]\n",
      " [0.93115316]\n",
      " [0.80636619]\n",
      " [0.3005005 ]\n",
      " [0.90672854]\n",
      " [0.91835441]\n",
      " [0.94370815]\n",
      " [0.91329778]\n",
      " [0.88181255]\n",
      " [0.31139241]\n",
      " [0.83925222]\n",
      " [0.53462741]\n",
      " [0.86912174]\n",
      " [0.33521686]\n",
      " [0.93138772]\n",
      " [0.9724458 ]\n",
      " [0.79283453]\n",
      " [0.78981407]\n",
      " [0.73142421]\n",
      " [0.76652161]\n",
      " [0.5320754 ]\n",
      " [0.92614829]\n",
      " [0.98806275]\n",
      " [0.90905913]\n",
      " [0.51528921]\n",
      " [0.16504717]\n",
      " [0.66092252]\n",
      " [0.76444458]\n",
      " [0.97807556]\n",
      " [0.77814541]\n",
      " [0.75748082]\n",
      " [0.96632178]\n",
      " [0.65317235]\n",
      " [0.93295983]\n",
      " [0.84545039]\n",
      " [0.41203825]\n",
      " [0.2610272 ]\n",
      " [0.95641582]\n",
      " [0.90476943]\n",
      " [0.33098702]\n",
      " [0.47652684]\n",
      " [0.64511856]\n",
      " [0.85468305]\n",
      " [0.89915659]\n",
      " [0.9568116 ]\n",
      " [0.05462904]\n",
      " [0.73163351]\n",
      " [0.87434237]\n",
      " [0.69662073]\n",
      " [0.66886039]\n",
      " [0.62158826]\n",
      " [0.62309609]\n",
      " [0.83441036]\n",
      " [0.84264407]\n",
      " [0.71803956]\n",
      " [0.43506925]\n",
      " [0.36201832]\n",
      " [0.32144704]\n",
      " [0.79793237]\n",
      " [0.96400514]\n",
      " [0.81462501]\n",
      " [0.81873584]\n",
      " [0.88038501]\n",
      " [0.48497961]\n",
      " [0.80660312]\n",
      " [0.83328916]\n",
      " [0.73521313]\n",
      " [0.87852795]\n",
      " [0.65763127]\n",
      " [0.4963809 ]\n",
      " [0.73028617]\n",
      " [0.95042818]\n",
      " [0.76760789]\n",
      " [0.43004091]\n",
      " [0.95941594]\n",
      " [0.59893644]\n",
      " [0.85573542]\n",
      " [0.21481479]\n",
      " [0.31105685]\n",
      " [0.04534951]\n",
      " [0.13953025]\n",
      " [0.93318123]\n",
      " [0.90114208]\n",
      " [0.96430703]\n",
      " [0.05568623]\n",
      " [0.56370874]\n",
      " [0.78214281]\n",
      " [0.54776368]\n",
      " [0.89591013]\n",
      " [0.46249181]\n",
      " [0.84010347]\n",
      " [0.57353595]\n",
      " [0.68016902]\n",
      " [0.75741902]\n",
      " [0.91121749]\n",
      " [0.83732792]\n",
      " [0.56963912]\n",
      " [0.91847663]\n",
      " [0.86446628]\n",
      " [0.96829724]\n",
      " [0.15404668]\n",
      " [0.88038278]\n",
      " [0.11278946]\n",
      " [0.28128132]\n",
      " [0.35876012]\n",
      " [0.94596486]\n",
      " [0.62368215]\n",
      " [0.94945657]\n",
      " [0.94808188]\n",
      " [0.63863107]\n",
      " [0.07185785]\n",
      " [0.1363137 ]\n",
      " [0.66771028]\n",
      " [0.79583902]\n",
      " [0.64489091]\n",
      " [0.89158643]\n",
      " [0.60998333]\n",
      " [0.31442866]\n",
      " [0.09204808]\n",
      " [0.93544687]\n",
      " [0.30453368]\n",
      " [0.91158205]\n",
      " [0.92988826]\n",
      " [0.71193864]\n",
      " [0.59904304]\n",
      " [0.6587373 ]\n",
      " [0.52958724]\n",
      " [0.75903086]\n",
      " [0.97250927]\n",
      " [0.76265329]\n",
      " [0.8769744 ]\n",
      " [0.0666415 ]\n",
      " [0.30156209]\n",
      " [0.9191424 ]\n",
      " [0.14526653]\n",
      " [0.95867432]\n",
      " [0.20726545]\n",
      " [0.21422589]\n",
      " [0.3260475 ]\n",
      " [0.73431049]\n",
      " [0.12166636]\n",
      " [0.73995528]\n",
      " [0.73216977]\n",
      " [0.86606579]\n",
      " [0.65113296]\n",
      " [0.08072941]\n",
      " [0.3531856 ]\n",
      " [0.7649216 ]\n",
      " [0.48282172]\n",
      " [0.95229043]\n",
      " [0.95544232]\n",
      " [0.73133025]\n",
      " [0.23800669]\n",
      " [0.01661484]\n",
      " [0.57631985]\n",
      " [0.27997697]\n",
      " [0.34083058]\n",
      " [0.97603282]\n",
      " [0.63192194]\n",
      " [0.96919158]\n",
      " [0.12599918]\n",
      " [0.07357988]\n",
      " [0.24403935]\n",
      " [0.87375308]\n",
      " [0.94050025]\n",
      " [0.90653264]\n",
      " [0.66709593]\n",
      " [0.6529172 ]\n",
      " [0.52329373]\n",
      " [0.10852196]\n",
      " [0.56798746]\n",
      " [0.06080812]\n",
      " [0.54723218]\n",
      " [0.91167949]\n",
      " [0.67509601]\n",
      " [0.78122647]\n",
      " [0.97489937]\n",
      " [0.83629363]\n",
      " [0.80169997]\n",
      " [0.7696273 ]\n",
      " [0.78786761]\n",
      " [0.89107155]\n",
      " [0.28531072]\n",
      " [0.30066435]\n",
      " [0.50093802]\n",
      " [0.85557749]\n",
      " [0.6495685 ]\n",
      " [0.69340142]\n",
      " [0.83129146]\n",
      " [0.248456  ]\n",
      " [0.40444826]\n",
      " [0.65532734]\n",
      " [0.63722124]\n",
      " [0.36043407]\n",
      " [0.93211234]\n",
      " [0.85135974]\n",
      " [0.95745748]\n",
      " [0.56777181]\n",
      " [0.76507824]\n",
      " [0.85401719]\n",
      " [0.85364622]\n",
      " [0.76166964]\n",
      " [0.89444714]\n",
      " [0.27658637]\n",
      " [0.54421484]\n",
      " [0.70054284]\n",
      " [0.36286866]\n",
      " [0.88110141]\n",
      " [0.23455851]\n",
      " [0.54778002]\n",
      " [0.96186815]\n",
      " [0.79189645]\n",
      " [0.88742883]\n",
      " [0.65503968]\n",
      " [0.39614259]\n",
      " [0.53319204]\n",
      " [0.38700989]\n",
      " [0.35468746]\n",
      " [0.66352159]\n",
      " [0.66429845]\n",
      " [0.64550843]\n",
      " [0.7149058 ]\n",
      " [0.14485157]\n",
      " [0.63705964]\n",
      " [0.93598568]\n",
      " [0.41369514]\n",
      " [0.7173016 ]\n",
      " [0.74287783]\n",
      " [0.44099843]\n",
      " [0.74330142]\n",
      " [0.47611458]\n",
      " [0.69991256]\n",
      " [0.94006081]\n",
      " [0.62681237]\n",
      " [0.70375792]\n",
      " [0.8575153 ]\n",
      " [0.55757295]\n",
      " [0.86166899]\n",
      " [0.97351121]\n",
      " [0.25460422]\n",
      " [0.76789094]\n",
      " [0.23584509]\n",
      " [0.7792315 ]\n",
      " [0.84671225]\n",
      " [0.73339912]\n",
      " [0.37343002]\n",
      " [0.80479337]\n",
      " [0.75663344]\n",
      " [0.72596858]\n",
      " [0.118152  ]\n",
      " [0.80536012]\n",
      " [0.87754287]\n",
      " [0.64019118]\n",
      " [0.95238265]\n",
      " [0.13090854]\n",
      " [0.80517511]\n",
      " [0.9686535 ]\n",
      " [0.10783975]\n",
      " [0.4438864 ]\n",
      " [0.73713876]\n",
      " [0.26990533]\n",
      " [0.11313687]\n",
      " [0.87209598]\n",
      " [0.94921741]\n",
      " [0.89012892]\n",
      " [0.65998683]\n",
      " [0.68799857]\n",
      " [0.55219865]\n",
      " [0.73060141]\n",
      " [0.87208032]\n",
      " [0.96083871]\n",
      " [0.7415493 ]\n",
      " [0.78122561]\n",
      " [0.63056582]\n",
      " [0.96390853]\n",
      " [0.95940989]\n",
      " [0.73862485]\n",
      " [0.26353347]\n",
      " [0.64362593]\n",
      " [0.24897917]\n",
      " [0.78372497]\n",
      " [0.12069894]\n",
      " [0.1663884 ]\n",
      " [0.39859085]\n",
      " [0.75936589]\n",
      " [0.31379865]\n",
      " [0.51598835]\n",
      " [0.84012746]\n",
      " [0.70965744]\n",
      " [0.90705676]\n",
      " [0.97355807]\n",
      " [0.80598202]\n",
      " [0.05558581]\n",
      " [0.41071834]\n",
      " [0.84779357]\n",
      " [0.86215437]\n",
      " [0.61714972]\n",
      " [0.22091912]\n",
      " [0.9285546 ]\n",
      " [0.90381178]\n",
      " [0.17278096]\n",
      " [0.6299762 ]\n",
      " [0.87122415]\n",
      " [0.91021815]\n",
      " [0.89252827]\n",
      " [0.93506516]\n",
      " [0.90935365]\n",
      " [0.93972125]\n",
      " [0.70647237]\n",
      " [0.62717921]\n",
      " [0.54611543]\n",
      " [0.85946569]\n",
      " [0.89918896]\n",
      " [0.13172237]\n",
      " [0.84562099]\n",
      " [0.91657208]\n",
      " [0.29523193]\n",
      " [0.61490446]\n",
      " [0.90280999]\n",
      " [0.51882434]\n",
      " [0.9616858 ]\n",
      " [0.1752724 ]\n",
      " [0.87106835]\n",
      " [0.61915709]\n",
      " [0.92250065]\n",
      " [0.28602672]\n",
      " [0.57773627]\n",
      " [0.77798777]\n",
      " [0.8673658 ]\n",
      " [0.07353438]\n",
      " [0.12890038]\n",
      " [0.73792206]\n",
      " [0.83362673]\n",
      " [0.3683935 ]\n",
      " [0.81265277]\n",
      " [0.40699587]\n",
      " [0.29849569]\n",
      " [0.89231716]\n",
      " [0.39968104]\n",
      " [0.96793184]\n",
      " [0.84184249]\n",
      " [0.62635119]\n",
      " [0.94641345]\n",
      " [0.61429001]\n",
      " [0.81619428]\n",
      " [0.22329265]\n",
      " [0.19105254]\n",
      " [0.78042657]\n",
      " [0.31094302]\n",
      " [0.42991862]\n",
      " [0.92265965]\n",
      " [0.94309058]\n",
      " [0.9378757 ]\n",
      " [0.96890194]\n",
      " [0.7552828 ]\n",
      " [0.93262086]\n",
      " [0.24996044]\n",
      " [0.31746976]\n",
      " [0.48974507]\n",
      " [0.97321218]\n",
      " [0.64228624]\n",
      " [0.13569953]\n",
      " [0.94775547]\n",
      " [0.81512426]\n",
      " [0.62316805]\n",
      " [0.81784298]\n",
      " [0.00458467]\n",
      " [0.94894814]\n",
      " [0.80167525]\n",
      " [0.76058998]\n",
      " [0.78163352]\n",
      " [0.98253475]\n",
      " [0.67170679]\n",
      " [0.76557393]\n",
      " [0.81612169]\n",
      " [0.8383518 ]\n",
      " [0.11537186]\n",
      " [0.6381576 ]\n",
      " [0.93578574]\n",
      " [0.63710043]\n",
      " [0.81376329]\n",
      " [0.97563828]\n",
      " [0.87539636]\n",
      " [0.93149934]\n",
      " [0.66805852]\n",
      " [0.81250497]\n",
      " [0.95775518]\n",
      " [0.74033973]\n",
      " [0.66284111]\n",
      " [0.19085867]\n",
      " [0.40007607]\n",
      " [0.50470945]\n",
      " [0.55882221]\n",
      " [0.58842596]\n",
      " [0.82169977]\n",
      " [0.62480345]\n",
      " [0.82207879]\n",
      " [0.88021393]\n",
      " [0.78699554]\n",
      " [0.71289271]\n",
      " [0.40836271]\n",
      " [0.61262455]\n",
      " [0.95490244]\n",
      " [0.86852805]\n",
      " [0.14778563]\n",
      " [0.32862399]\n",
      " [0.39819055]\n",
      " [0.0451289 ]\n",
      " [0.92931222]\n",
      " [0.12281879]\n",
      " [0.91221579]\n",
      " [0.92165135]\n",
      " [0.86531939]\n",
      " [0.69428202]\n",
      " [0.91955408]\n",
      " [0.35060124]\n",
      " [0.84045685]\n",
      " [0.960455  ]\n",
      " [0.24808529]\n",
      " [0.40950723]\n",
      " [0.92208191]\n",
      " [0.89735112]\n",
      " [0.642249  ]\n",
      " [0.82450293]\n",
      " [0.84229059]\n",
      " [0.87125087]\n",
      " [0.19604401]\n",
      " [0.7636545 ]\n",
      " [0.91325795]\n",
      " [0.71195626]\n",
      " [0.84857037]\n",
      " [0.73553536]\n",
      " [0.88427681]\n",
      " [0.91305803]\n",
      " [0.94996135]\n",
      " [0.54065628]\n",
      " [0.41814988]\n",
      " [0.81666336]\n",
      " [0.84683428]\n",
      " [0.98492196]\n",
      " [0.78787534]\n",
      " [0.70367197]\n",
      " [0.3823237 ]\n",
      " [0.72278557]\n",
      " [0.95688859]\n",
      " [0.97497831]\n",
      " [0.92338687]\n",
      " [0.71056847]\n",
      " [0.73670696]\n",
      " [0.81135088]\n",
      " [0.40638186]\n",
      " [0.81358723]\n",
      " [0.84653751]\n",
      " [0.91180328]\n",
      " [0.59766496]\n",
      " [0.796756  ]\n",
      " [0.95092183]\n",
      " [0.46434033]\n",
      " [0.54818617]\n",
      " [0.64570938]\n",
      " [0.73050091]\n",
      " [0.71257963]\n",
      " [0.9253984 ]\n",
      " [0.94916315]\n",
      " [0.15131189]\n",
      " [0.06039981]\n",
      " [0.74747965]\n",
      " [0.4878396 ]\n",
      " [0.24484196]\n",
      " [0.88012149]\n",
      " [0.92972858]\n",
      " [0.78819905]\n",
      " [0.95392315]\n",
      " [0.92590916]\n",
      " [0.80717647]\n",
      " [0.85497439]\n",
      " [0.76808726]\n",
      " [0.46841693]\n",
      " [0.8348622 ]\n",
      " [0.62420019]\n",
      " [0.04899601]\n",
      " [0.91538204]\n",
      " [0.90662702]\n",
      " [0.7872401 ]\n",
      " [0.93772242]\n",
      " [0.86717336]\n",
      " [0.90304668]\n",
      " [0.54770899]\n",
      " [0.67011259]\n",
      " [0.92487489]\n",
      " [0.84192273]\n",
      " [0.8715229 ]\n",
      " [0.91474499]\n",
      " [0.62473337]\n",
      " [0.76658307]\n",
      " [0.84653518]\n",
      " [0.50535509]\n",
      " [0.55974737]\n",
      " [0.06185983]\n",
      " [0.19616615]\n",
      " [0.87379731]\n",
      " [0.69119345]\n",
      " [0.68938746]\n",
      " [0.59577088]\n",
      " [0.96161077]\n",
      " [0.38460406]\n",
      " [0.87739598]\n",
      " [0.21385019]\n",
      " [0.94968785]\n",
      " [0.26297377]\n",
      " [0.78140491]\n",
      " [0.58824775]\n",
      " [0.88631178]\n",
      " [0.58328012]\n",
      " [0.1659829 ]\n",
      " [0.80094588]\n",
      " [0.93844139]\n",
      " [0.29842991]\n",
      " [0.93312825]\n",
      " [0.92228314]\n",
      " [0.90759449]\n",
      " [0.85667407]\n",
      " [0.35163298]\n",
      " [0.25714492]\n",
      " [0.65980717]\n",
      " [0.10870895]\n",
      " [0.97448802]\n",
      " [0.25377524]\n",
      " [0.94831387]\n",
      " [0.88834077]\n",
      " [0.29999882]\n",
      " [0.14794085]\n",
      " [0.74248428]\n",
      " [0.36412572]\n",
      " [0.89533823]\n",
      " [0.80379432]\n",
      " [0.99099687]\n",
      " [0.61103967]\n",
      " [0.63625778]\n",
      " [0.8029224 ]\n",
      " [0.8769099 ]\n",
      " [0.04308884]\n",
      " [0.703682  ]\n",
      " [0.8420119 ]\n",
      " [0.87969569]\n",
      " [0.69927058]\n",
      " [0.47450373]\n",
      " [0.6194232 ]\n",
      " [0.94027686]\n",
      " [0.6852926 ]\n",
      " [0.80663292]\n",
      " [0.8644578 ]\n",
      " [0.89541704]\n",
      " [0.86365384]\n",
      " [0.6156239 ]\n",
      " [0.85165238]\n",
      " [0.92624712]\n",
      " [0.68232492]\n",
      " [0.9790849 ]\n",
      " [0.84978228]\n",
      " [0.62027683]\n",
      " [0.5129654 ]\n",
      " [0.88143289]\n",
      " [0.89129343]\n",
      " [0.38749747]\n",
      " [0.67187025]\n",
      " [0.11865794]\n",
      " [0.59962392]\n",
      " [0.84939235]\n",
      " [0.96565905]\n",
      " [0.82745166]\n",
      " [0.7336954 ]\n",
      " [0.79026896]\n",
      " [0.90220376]\n",
      " [0.36324795]\n",
      " [0.95857655]\n",
      " [0.55410847]\n",
      " [0.88772878]\n",
      " [0.31875915]\n",
      " [0.03801094]\n",
      " [0.2508121 ]\n",
      " [0.28390106]\n",
      " [0.69404133]\n",
      " [0.85606215]\n",
      " [0.57962401]\n",
      " [0.78904158]\n",
      " [0.81514858]\n",
      " [0.466167  ]\n",
      " [0.28375496]\n",
      " [0.9291781 ]\n",
      " [0.93745999]\n",
      " [0.26993732]\n",
      " [0.72604602]\n",
      " [0.12840288]\n",
      " [0.44284582]\n",
      " [0.75994662]\n",
      " [0.67399436]\n",
      " [0.93117902]\n",
      " [0.98924069]\n",
      " [0.0916012 ]\n",
      " [0.66276671]\n",
      " [0.65078611]\n",
      " [0.44627305]\n",
      " [0.72465737]\n",
      " [0.79663255]\n",
      " [0.90887302]\n",
      " [0.7731352 ]\n",
      " [0.38078215]\n",
      " [0.76124336]\n",
      " [0.13103507]\n",
      " [0.63332708]\n",
      " [0.46384597]\n",
      " [0.94997504]\n",
      " [0.60375282]\n",
      " [0.51793636]\n",
      " [0.85556907]\n",
      " [0.73333314]\n",
      " [0.38427188]\n",
      " [0.75060484]\n",
      " [0.70138552]\n",
      " [0.27774403]\n",
      " [0.54997161]\n",
      " [0.9151529 ]\n",
      " [0.86775159]\n",
      " [0.58143546]\n",
      " [0.73975994]\n",
      " [0.24791718]\n",
      " [0.84852974]\n",
      " [0.53512712]\n",
      " [0.78323488]\n",
      " [0.30704326]\n",
      " [0.64822908]\n",
      " [0.88751458]\n",
      " [0.08715514]\n",
      " [0.23029621]\n",
      " [0.87486484]\n",
      " [0.81876191]\n",
      " [0.81900158]\n",
      " [0.94780455]\n",
      " [0.77187874]\n",
      " [0.68753322]\n",
      " [0.72426414]\n",
      " [0.84119082]\n",
      " [0.69538936]\n",
      " [0.80398079]\n",
      " [0.48664278]\n",
      " [0.50805032]\n",
      " [0.91248178]\n",
      " [0.82684862]\n",
      " [0.72815374]\n",
      " [0.17747427]\n",
      " [0.89753554]\n",
      " [0.89177495]\n",
      " [0.84623517]\n",
      " [0.72271893]\n",
      " [0.9237612 ]\n",
      " [0.86112953]\n",
      " [0.78612036]\n",
      " [0.34035558]\n",
      " [0.8925785 ]\n",
      " [0.92645753]\n",
      " [0.35124183]\n",
      " [0.10393089]\n",
      " [0.78497264]\n",
      " [0.29848964]\n",
      " [0.78202627]\n",
      " [0.20534818]\n",
      " [0.44772065]\n",
      " [0.4288584 ]\n",
      " [0.76328843]\n",
      " [0.90462377]\n",
      " [0.08094642]\n",
      " [0.33735588]\n",
      " [0.61133451]\n",
      " [0.5338235 ]\n",
      " [0.49485111]\n",
      " [0.81367441]\n",
      " [0.1159716 ]\n",
      " [0.93872949]\n",
      " [0.09507345]\n",
      " [0.91233346]\n",
      " [0.76162287]\n",
      " [0.7143832 ]\n",
      " [0.86526348]\n",
      " [0.73316535]\n",
      " [0.92882251]] \n",
      "Correct(y):  [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      " Accuracy: 0.769433465085639\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "\n",
    "# 파일 읽기  -> 몸무게, 나이, 혈중 지방 함량이 제공되는 데이터\n",
    "data_set = np.loadtxt(\"./dataset/data-03-diabetes.csv\",delimiter=\",\", dtype=np.float32)\n",
    "# 데이터 추출\n",
    "x_data = data_set[:,0:-1]\n",
    "y_data = data_set[:, [-1]]  \n",
    "\n",
    "X = tf.placeholder(tf.float64, shape=[None, 8])\n",
    "Y = tf.placeholder(tf.float64, shape=[None, 1])\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([8,1], dtype=tf.float64))\n",
    "b = tf.Variable(tf.random_uniform([1], dtype=tf.float64))\n",
    "\n",
    "y = tf.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "loss = -tf.reduce_mean(Y* tf.log(y) + (1-Y) * tf.log(1-y))\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "predicted = tf.cast(y >0.5,dtype=tf.float64)\n",
    "# reduce_mean:배열의 평균을 구함.   cast: 실제값과 예측값이 같은지 \n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y), dtype=tf.float64)) \n",
    "\n",
    "\n",
    "#학습\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        W_,b_,loss_,_=sess.run([W,b,loss,gradient_descent], feed_dict={X:x_data, Y:y_data})\n",
    "        if(step +1) % 200 == 0: \n",
    "            print(\"step=%d, W1=%.4f, W2=%.4f, W3=%.4f,W4=%.4f,W5=%.4f,W6=%.4f,W7=%.4f,W8=%.4f, b=%.4f, loss=%.4f\" %(step+1, W_[0], W_[1],W_[2],W_[3],W_[4],W_[5],W_[6],W_[7],b_,loss_) )\n",
    "            \n",
    "    #정확도 측정\n",
    "    h,c,a=sess.run([y,predicted,accuracy], feed_dict ={X:x_data, Y:y_data})\n",
    "    print(\"\\nHypothesis:\",h,\"\\nCorrect(y): \",c,\"\\n Accuracy:\",a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
